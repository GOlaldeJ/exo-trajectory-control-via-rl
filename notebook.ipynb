{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "\n",
    "# Initialize PyBullet\n",
    "physicsClient = p.connect(p.GUI)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.setGravity(0, 0, -9.81)\n",
    "\n",
    "# Load ground plane\n",
    "planeId = p.loadURDF(\"plane.urdf\")\n",
    "\n",
    "# Load exoskeleton\n",
    "startPos = [0, 0, 1.215]  # Start position above ground\n",
    "startOrientation = p.getQuaternionFromEuler([0, 0, 0])\n",
    "robotId = p.loadURDF(\"urdf/Exoskeleton.urdf\", startPos, startOrientation)\n",
    "\n",
    "# Get joint information\n",
    "numJoints = p.getNumJoints(robotId)\n",
    "jointInfoList = []\n",
    "for i in range(numJoints):\n",
    "    jointInfo = p.getJointInfo(robotId, i)\n",
    "    jointInfoList.append(jointInfo)\n",
    "    print(f\"Joint {i}: {jointInfo[1].decode('utf-8')}\")\n",
    "\n",
    "# Set initial joint positions for standing\n",
    "jointPositions = {\n",
    "    'right_hip_yaw_joint': -0.15,\n",
    "    'right_hip_roll_joint': 0.0,\n",
    "    'right_hip_pitch_joint': -0.025,\n",
    "    'right_knee_joint': 0.225,\n",
    "    'right_ankle_roll_joint': 0.0,\n",
    "    'right_ankle_pitch_joint': -0.2,\n",
    "    'left_hip_yaw_joint': 0.15,\n",
    "    'left_hip_roll_joint': 0.0,\n",
    "    'left_hip_pitch_joint': -0.025,\n",
    "    'left_knee_joint': 0.225,\n",
    "    'left_ankle_roll_joint': 0.0,\n",
    "    'left_ankle_pitch_joint': -0.2\n",
    "}\n",
    "\n",
    "# Apply initial joint positions\n",
    "for joint_name, position in jointPositions.items():\n",
    "    for i in range(numJoints):\n",
    "        if jointInfoList[i][1].decode('utf-8') == joint_name:\n",
    "            p.resetJointState(robotId, i, position)\n",
    "            p.setJointMotorControl2(\n",
    "                robotId, i, p.POSITION_CONTROL,\n",
    "                targetPosition=position,\n",
    "                force=200\n",
    "            )\n",
    "            break\n",
    "\n",
    "# Configure debug visualizer\n",
    "p.resetDebugVisualizerCamera(\n",
    "    cameraDistance=2,\n",
    "    cameraYaw=0,\n",
    "    cameraPitch=-30,\n",
    "    cameraTargetPosition=[0, 0, 1]\n",
    ")\n",
    "\n",
    "# Simulation loop\n",
    "try:\n",
    "    while True:\n",
    "        p.stepSimulation()\n",
    "        time.sleep(1./240.)\n",
    "except KeyboardInterrupt:\n",
    "    p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4893bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "\n",
    "class ExoskeletonEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, render: bool = False, task: str = \"stand\"):\n",
    "        super(ExoskeletonEnv, self).__init__()\n",
    "        self.render_mode = render\n",
    "        self.task = task\n",
    "\n",
    "        # Connect to PyBullet in GUI or DIRECT mode\n",
    "        if self.render_mode:\n",
    "            self.physicsClient = p.connect(p.GUI)\n",
    "        else:\n",
    "            self.physicsClient = p.connect(p.DIRECT)\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        p.setGravity(0, 0, -9.81)\n",
    "        \n",
    "        # Load the ground plane and exoskeleton URDF\n",
    "        self.planeId = p.loadURDF(\"plane.urdf\")\n",
    "        self.startPos = [0, 0, 1.215]\n",
    "        self.startOrientation = p.getQuaternionFromEuler([0, 0, 0])\n",
    "        self.robotId = p.loadURDF(\"urdf/Exoskeleton.urdf\", self.startPos, self.startOrientation)\n",
    "        \n",
    "        # Define the controlled joints\n",
    "        self.joint_names = [\n",
    "            'right_hip_yaw_joint', 'right_hip_roll_joint', 'right_hip_pitch_joint', \n",
    "            'right_knee_joint', 'right_ankle_roll_joint', 'right_ankle_pitch_joint',\n",
    "            'left_hip_yaw_joint', 'left_hip_roll_joint', 'left_hip_pitch_joint', \n",
    "            'left_knee_joint', 'left_ankle_roll_joint', 'left_ankle_pitch_joint'\n",
    "        ]\n",
    "        self.joint_indices = {}\n",
    "        self.num_joints = p.getNumJoints(self.robotId)\n",
    "        for i in range(self.num_joints):\n",
    "            info = p.getJointInfo(self.robotId, i)\n",
    "            name = info[1].decode('utf-8')\n",
    "            if name in self.joint_names:\n",
    "                self.joint_indices[name] = i\n",
    "\n",
    "        # Default (standing) joint positions as offsets\n",
    "        self.default_joint_positions = {\n",
    "            'right_hip_yaw_joint': -0.15, \n",
    "            'right_hip_roll_joint': 0.0, \n",
    "            'right_hip_pitch_joint': -0.025,\n",
    "            'right_knee_joint': 0.225, \n",
    "            'right_ankle_roll_joint': 0.0, \n",
    "            'right_ankle_pitch_joint': -0.2,\n",
    "            'left_hip_yaw_joint': 0.15, \n",
    "            'left_hip_roll_joint': 0.0, \n",
    "            'left_hip_pitch_joint': -0.025,\n",
    "            'left_knee_joint': 0.225, \n",
    "            'left_ankle_roll_joint': 0.0, \n",
    "            'left_ankle_pitch_joint': -0.2\n",
    "        }\n",
    "        \n",
    "        # Action space: small deviations (offsets) for each joint.\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1.0, high=1.0, shape=(len(self.joint_names),), dtype=np.float32\n",
    "        )\n",
    "        # Observation space: joint positions, velocities, base position (3) and base orientation (3 Euler angles).\n",
    "        # Total observation dimension: 12 joints * 2 + 6 + 6 = 36.\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(36,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Initialize smoothed action\n",
    "        self.prev_action = np.zeros(len(self.joint_names), dtype=np.float32)\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        smoothing_factor = 0.05  # Adjust for smoother transitions\n",
    "        self.prev_action = (1 - smoothing_factor) * self.prev_action + smoothing_factor * action\n",
    "        \n",
    "        # Compute target positions for each joint.\n",
    "        joint_indices = [self.joint_indices[name] for name in self.joint_names]\n",
    "        target_positions = []\n",
    "\n",
    "        for idx, name in enumerate(self.joint_names):\n",
    "            joint_index = self.joint_indices[name]\n",
    "            \n",
    "            # Get the physical joint limits from the URDF\n",
    "            joint_info = p.getJointInfo(self.robotId, joint_index)\n",
    "            joint_lower_limit = joint_info[8]  # Lower limit in radians\n",
    "            joint_upper_limit = joint_info[9]  # Upper limit in radians\n",
    "\n",
    "            # Map the action (in [-1, 1]) to the joint's physical range\n",
    "            scaled_position = joint_lower_limit + (self.prev_action[idx] + 1) / 2 * (joint_upper_limit - joint_lower_limit)\n",
    "            \n",
    "            # Append the target position for the joint\n",
    "            target_positions.append(scaled_position)\n",
    "        \n",
    "        # Apply control to all joints at once using setJointMotorControlArray.\n",
    "        p.setJointMotorControlArray(\n",
    "            self.robotId,\n",
    "            jointIndices=joint_indices,\n",
    "            controlMode=p.POSITION_CONTROL,\n",
    "            targetPositions=target_positions,\n",
    "            forces=[200] * len(joint_indices),\n",
    "        )\n",
    "        \n",
    "        p.stepSimulation()\n",
    "        time.sleep(1./240.)\n",
    "        self.elapsed_time += 1 / 240  # Assuming 240Hz simulation\n",
    "        \n",
    "        # Gather joint positions and velocities.\n",
    "        joint_positions = []\n",
    "        joint_velocities = []\n",
    "        for joint_name in self.joint_names:\n",
    "            joint_index = self.joint_indices[joint_name]\n",
    "            joint_state = p.getJointState(self.robotId, joint_index)\n",
    "            joint_positions.append(joint_state[0])\n",
    "            joint_velocities.append(joint_state[1])\n",
    "\n",
    "        # Get base position, orientation and velocities.\n",
    "        base_pos, base_orient_quat = p.getBasePositionAndOrientation(self.robotId)\n",
    "        base_orient_euler = p.getEulerFromQuaternion(base_orient_quat)\n",
    "        base_linear_vel, base_angular_vel = p.getBaseVelocity(self.robotId)\n",
    "        \n",
    "        # Concatenate joint states with base state information.\n",
    "        obs = np.array(\n",
    "            joint_positions + \n",
    "            joint_velocities + \n",
    "            list(base_pos) + \n",
    "            list(base_orient_euler) +\n",
    "            list(base_linear_vel) +\n",
    "            list(base_angular_vel), \n",
    "            dtype=np.float32)\n",
    "        \n",
    "        # Use the new reward function.\n",
    "        reward, reward_components = self._calculate_reward()\n",
    "\n",
    "        # End episode if base falls below a threshold.\n",
    "        done = (\n",
    "            bool(base_pos[2] < 0.5) or \n",
    "            bool(abs(base_orient_euler[0]) > 1) or \n",
    "            bool(abs(base_orient_euler[1]) > 1) or\n",
    "            self.elapsed_time > 20  # 20s timer\n",
    "            )\n",
    "        truncated = False\n",
    "        \n",
    "        return obs, reward, done, truncated, {\"reward_components\": reward_components}\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        p.resetSimulation()\n",
    "        p.setGravity(0, 0, -9.81)\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        p.loadURDF(\"plane.urdf\")\n",
    "        self.robotId = p.loadURDF(\"urdf/Exoskeleton.urdf\", self.startPos, self.startOrientation)\n",
    "        \n",
    "        self.elapsed_time = 0  # Timer set to 0\n",
    "\n",
    "        # Reset smoothed action\n",
    "        self.prev_action = np.zeros(len(self.joint_names), dtype=np.float32)  \n",
    "        \n",
    "        # Update joint indices.\n",
    "        self.joint_indices = {}\n",
    "        self.num_joints = p.getNumJoints(self.robotId)\n",
    "        for i in range(self.num_joints):\n",
    "            info = p.getJointInfo(self.robotId, i)\n",
    "            name = info[1].decode('utf-8')\n",
    "            if name in self.joint_names:\n",
    "                self.joint_indices[name] = i\n",
    "        \n",
    "        # Reset joints to default positions.\n",
    "        for joint_name in self.joint_names:\n",
    "            joint_index = self.joint_indices[joint_name]\n",
    "            p.resetJointState(self.robotId, joint_index, self.default_joint_positions[joint_name])\n",
    "        \n",
    "        if self.task == \"stand\":\n",
    "            # Apply a random push in the xy plane to the robot's base.\n",
    "            self.random_push = np.random.uniform(low=-3, high=3, size=2) #+-1.5\n",
    "            p.resetBaseVelocity(self.robotId, linearVelocity=[self.random_push[0], self.random_push[1], 0])\n",
    "        \n",
    "        joint_positions = []\n",
    "        joint_velocities = []\n",
    "        for joint_name in self.joint_names:\n",
    "            joint_index = self.joint_indices[joint_name]\n",
    "            joint_state = p.getJointState(self.robotId, joint_index)\n",
    "            joint_positions.append(joint_state[0])\n",
    "            joint_velocities.append(joint_state[1])\n",
    "        \n",
    "        base_pos, base_orient_quat = p.getBasePositionAndOrientation(self.robotId)\n",
    "        base_orient_euler = p.getEulerFromQuaternion(base_orient_quat)\n",
    "        base_linear_vel, base_angular_vel = p.getBaseVelocity(self.robotId)\n",
    "        \n",
    "        # Concatenate joint states with base state information.\n",
    "        obs = np.array(\n",
    "            joint_positions + \n",
    "            joint_velocities + \n",
    "            list(base_pos) + \n",
    "            list(base_orient_euler) +\n",
    "            list(base_linear_vel) +\n",
    "            list(base_angular_vel), \n",
    "            dtype=np.float32)\n",
    "        \n",
    "        return obs, {}\n",
    "    \n",
    "    def _calculate_reward(self):\n",
    "        positions = []\n",
    "        velocities = []\n",
    "        torques = []\n",
    "        \n",
    "        for joint_name in self.joint_names:\n",
    "            joint_index = self.joint_indices[joint_name]\n",
    "            joint_state = p.getJointState(self.robotId, joint_index)\n",
    "            \n",
    "            # Store position difference from default\n",
    "            current_pos = joint_state[0]\n",
    "            target_pos = self.default_joint_positions[joint_name]\n",
    "            positions.append(current_pos - target_pos)\n",
    "            \n",
    "            # Store velocity and torque\n",
    "            velocities.append(joint_state[1])\n",
    "            torques.append(joint_state[3])\n",
    "        \n",
    "        base_pos, base_orient_quat = p.getBasePositionAndOrientation(self.robotId)\n",
    "        base_orient_euler = p.getEulerFromQuaternion(base_orient_quat)\n",
    "\n",
    "        time_reward = 1.0\n",
    "        height_reward = np.exp(-50 * (base_pos[2] - 1.215) ** 2)\n",
    "        upright_reward = np.exp(-5 * (base_orient_euler[0]** 2 + base_orient_euler[1]** 2 + base_orient_euler[2]**2))\n",
    "\n",
    "        position_penalty = np.exp(-1 * np.sum(np.square(positions))) - 1.0\n",
    "        velocity_penalty = np.exp(-0.01 * np.sum(np.square(velocities))) - 1.0\n",
    "        torque_penalty = np.exp(-1e-4 * np.sum(np.square(torques))) - 1.0\n",
    "\n",
    "        # Walk-specific rewards\n",
    "        travel_reward = base_pos[0]\n",
    "        drift_penalty = -1 * (base_pos[1] ** 2)\n",
    "\n",
    "        if self.task == \"stand\":\n",
    "            reward_components = {\n",
    "                'time': 1.0 * time_reward,\n",
    "                'height': 1.0 * height_reward,\n",
    "                'upright': 1.0 * upright_reward,\n",
    "                'position_penalty': 0.7 * position_penalty,\n",
    "                'velocity_penalty': 0.3 * velocity_penalty,\n",
    "                'torque_penalty': 0.3 * torque_penalty,\n",
    "            }\n",
    "        \n",
    "        if self.task == \"walk\":\n",
    "            reward_components = {\n",
    "                'time': 1.0 * time_reward,\n",
    "                'height': 1.0 * height_reward,\n",
    "                'upright': 1.0 * upright_reward,\n",
    "                'position_penalty': 0.7 * position_penalty,\n",
    "                'velocity_penalty': 0.3 * velocity_penalty,\n",
    "                'torque_penalty': 0.3 * torque_penalty,\n",
    "                'travel_reward': 0.5 * travel_reward,\n",
    "                'drift_penalty': 1.0 * drift_penalty, \n",
    "            }\n",
    "        \n",
    "        reward = sum(reward_components.values())\n",
    "\n",
    "        return reward, reward_components\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        p.disconnect()\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from collections import defaultdict\n",
    "\n",
    "class RewardComponentsCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.episode_components = None\n",
    "\n",
    "    def _init_callback(self):\n",
    "        self.episode_components = [defaultdict(float) for _ in range(self.training_env.num_envs)]\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        for env_idx in range(self.training_env.num_envs):\n",
    "            info = self.locals['infos'][env_idx]\n",
    "            if 'reward_components' in info:\n",
    "                components = info['reward_components']\n",
    "                for key, value in components.items():\n",
    "                    self.episode_components[env_idx][key] += value\n",
    "            if self.locals['dones'][env_idx]:\n",
    "                if self.episode_components[env_idx]:\n",
    "                    for key, value in self.episode_components[env_idx].items():\n",
    "                        self.logger.record(f\"reward_components/{key}\", value)\n",
    "                self.episode_components[env_idx] = defaultdict(float)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bf5661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./tensorboard\\test_1\n",
      "----------------------------------\n",
      "| reward_components/  |          |\n",
      "|    height           | 257      |\n",
      "|    position_penalty | -230     |\n",
      "|    time             | 343      |\n",
      "|    torque_penalty   | -103     |\n",
      "|    upright          | 146      |\n",
      "|    velocity_penalty | -29.5    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "| time/               |          |\n",
      "|    fps              | 1878     |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 24576    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 38.8        |\n",
      "|    position_penalty     | -59.2       |\n",
      "|    time                 | 95          |\n",
      "|    torque_penalty       | -28.5       |\n",
      "|    upright              | 60.9        |\n",
      "|    velocity_penalty     | -10.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 138         |\n",
      "|    ep_rew_mean          | 132         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009555297 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17         |\n",
      "|    explained_variance   | 0.000583    |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 52.4         |\n",
      "|    position_penalty     | -82.9        |\n",
      "|    time                 | 129          |\n",
      "|    torque_penalty       | -38.7        |\n",
      "|    upright              | 83           |\n",
      "|    velocity_penalty     | -15.3        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 134          |\n",
      "|    ep_rew_mean          | 124          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1795         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071134255 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -17          |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00199      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 63.4        |\n",
      "|    position_penalty     | -105        |\n",
      "|    time                 | 162         |\n",
      "|    torque_penalty       | -48.6       |\n",
      "|    upright              | 68.1        |\n",
      "|    velocity_penalty     | -15.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 145         |\n",
      "|    ep_rew_mean          | 131         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1785        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008638184 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -17         |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00199     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 43.5        |\n",
      "|    position_penalty     | -62.2       |\n",
      "|    time                 | 99          |\n",
      "|    torque_penalty       | -29.6       |\n",
      "|    upright              | 44.3        |\n",
      "|    velocity_penalty     | -11.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 135         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1778        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009711648 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.9       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.00198     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 76           |\n",
      "|    position_penalty     | -86.6        |\n",
      "|    time                 | 134          |\n",
      "|    torque_penalty       | -40.2        |\n",
      "|    upright              | 28.4         |\n",
      "|    velocity_penalty     | -12.5        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 142          |\n",
      "|    ep_rew_mean          | 133          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1774         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095806075 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -16.9        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.00198      |\n",
      "|    loss                 | 9.89         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 98.1        |\n",
      "|    position_penalty     | -76.2       |\n",
      "|    time                 | 120         |\n",
      "|    torque_penalty       | -36         |\n",
      "|    upright              | 26.1        |\n",
      "|    velocity_penalty     | -12.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 146         |\n",
      "|    ep_rew_mean          | 140         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1772        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009728576 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.9       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.00197     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 39.6        |\n",
      "|    position_penalty     | -60.6       |\n",
      "|    time                 | 96          |\n",
      "|    torque_penalty       | -28.8       |\n",
      "|    upright              | 64.8        |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 139         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1770        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009860824 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.8       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.00197     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 65.9         |\n",
      "|    position_penalty     | -94.8        |\n",
      "|    time                 | 146          |\n",
      "|    torque_penalty       | -43.8        |\n",
      "|    upright              | 54.9         |\n",
      "|    velocity_penalty     | -14.6        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 144          |\n",
      "|    ep_rew_mean          | 142          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1768         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113283135 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -16.8        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.00196      |\n",
      "|    loss                 | 8.66         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 86.5        |\n",
      "|    position_penalty     | -110        |\n",
      "|    time                 | 173         |\n",
      "|    torque_penalty       | -51.9       |\n",
      "|    upright              | 47.8        |\n",
      "|    velocity_penalty     | -14.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 138         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1766        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011683106 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.7       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.00196     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 288         |\n",
      "|    position_penalty     | -276        |\n",
      "|    time                 | 420         |\n",
      "|    torque_penalty       | -126        |\n",
      "|    upright              | 42.4        |\n",
      "|    velocity_penalty     | -32.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1766        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015095201 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.7       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00195     |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 104         |\n",
      "|    position_penalty     | -97.4       |\n",
      "|    time                 | 157         |\n",
      "|    torque_penalty       | -47.1       |\n",
      "|    upright              | 25.8        |\n",
      "|    velocity_penalty     | -13.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 149         |\n",
      "|    ep_rew_mean          | 150         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1758        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012245835 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.6       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00195     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 42.2        |\n",
      "|    position_penalty     | -70.7       |\n",
      "|    time                 | 115         |\n",
      "|    torque_penalty       | -34.5       |\n",
      "|    upright              | 67.2        |\n",
      "|    velocity_penalty     | -11.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | 142         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1756        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011380925 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.6       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.00194     |\n",
      "|    loss                 | 5.55        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 109         |\n",
      "|    position_penalty     | -74.7       |\n",
      "|    time                 | 117         |\n",
      "|    torque_penalty       | -35.1       |\n",
      "|    upright              | 32.5        |\n",
      "|    velocity_penalty     | -11.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 148         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1755        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013510898 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.6       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.00194     |\n",
      "|    loss                 | 5.48        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 136         |\n",
      "|    position_penalty     | -116        |\n",
      "|    time                 | 182         |\n",
      "|    torque_penalty       | -54.5       |\n",
      "|    upright              | 55.2        |\n",
      "|    velocity_penalty     | -15.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 148         |\n",
      "|    ep_rew_mean          | 156         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1753        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011544458 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.5       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.00193     |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.954       |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 126         |\n",
      "|    position_penalty     | -85.3       |\n",
      "|    time                 | 136         |\n",
      "|    torque_penalty       | -40.8       |\n",
      "|    upright              | 35.3        |\n",
      "|    velocity_penalty     | -13.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1753        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012387213 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00193     |\n",
      "|    loss                 | 4.79        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 44.6        |\n",
      "|    position_penalty     | -62.6       |\n",
      "|    time                 | 105         |\n",
      "|    torque_penalty       | -31.5       |\n",
      "|    upright              | 55.2        |\n",
      "|    velocity_penalty     | -9.56       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 148         |\n",
      "|    ep_rew_mean          | 156         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1754        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011720821 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.4       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.00192     |\n",
      "|    loss                 | 6.69        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.949       |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 108        |\n",
      "|    position_penalty     | -101       |\n",
      "|    time                 | 167        |\n",
      "|    torque_penalty       | -50.1      |\n",
      "|    upright              | 54.7       |\n",
      "|    velocity_penalty     | -13.3      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 158        |\n",
      "|    ep_rew_mean          | 174        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1755       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01123386 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -16.4      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.00192    |\n",
      "|    loss                 | 4.95       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    std                  | 0.945      |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 87.7        |\n",
      "|    position_penalty     | -58.5       |\n",
      "|    time                 | 95          |\n",
      "|    torque_penalty       | -28.5       |\n",
      "|    upright              | 34.9        |\n",
      "|    velocity_penalty     | -10.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 162         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1755        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012728966 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.3       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00191     |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 238         |\n",
      "|    position_penalty     | -182        |\n",
      "|    time                 | 282         |\n",
      "|    torque_penalty       | -84.5       |\n",
      "|    upright              | 135         |\n",
      "|    velocity_penalty     | -20.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 162         |\n",
      "|    ep_rew_mean          | 180         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1756        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014394329 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.3       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00191     |\n",
      "|    loss                 | 5.6         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 41.9        |\n",
      "|    position_penalty     | -58.1       |\n",
      "|    time                 | 98          |\n",
      "|    torque_penalty       | -29.4       |\n",
      "|    upright              | 69.8        |\n",
      "|    velocity_penalty     | -9.45       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 169         |\n",
      "|    ep_rew_mean          | 195         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1756        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011261347 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.2       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0019      |\n",
      "|    loss                 | 5.67        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 41.7        |\n",
      "|    position_penalty     | -54         |\n",
      "|    time                 | 98          |\n",
      "|    torque_penalty       | -29.4       |\n",
      "|    upright              | 63.3        |\n",
      "|    velocity_penalty     | -9.45       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | 182         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1756        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011217085 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.2       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0019      |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 49.8        |\n",
      "|    position_penalty     | -67.2       |\n",
      "|    time                 | 121         |\n",
      "|    torque_penalty       | -36.2       |\n",
      "|    upright              | 89.9        |\n",
      "|    velocity_penalty     | -10         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1757        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011479244 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.2       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00189     |\n",
      "|    loss                 | 5.84        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.932       |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 90.2        |\n",
      "|    position_penalty     | -74.2       |\n",
      "|    time                 | 115         |\n",
      "|    torque_penalty       | -34.5       |\n",
      "|    upright              | 38.9        |\n",
      "|    velocity_penalty     | -13.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 157         |\n",
      "|    ep_rew_mean          | 182         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1757        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011375628 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16.1       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00189     |\n",
      "|    loss                 | 5.88        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 145        |\n",
      "|    position_penalty     | -135       |\n",
      "|    time                 | 227        |\n",
      "|    torque_penalty       | -68        |\n",
      "|    upright              | 72.7       |\n",
      "|    velocity_penalty     | -17.9      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 164        |\n",
      "|    ep_rew_mean          | 192        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1757       |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 614400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01556423 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -16.1      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.00188    |\n",
      "|    loss                 | 4.72       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    std                  | 0.921      |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 89.7        |\n",
      "|    position_penalty     | -82.7       |\n",
      "|    time                 | 135         |\n",
      "|    torque_penalty       | -40.5       |\n",
      "|    upright              | 46.7        |\n",
      "|    velocity_penalty     | -12.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 163         |\n",
      "|    ep_rew_mean          | 192         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1758        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012974276 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16         |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00188     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 166         |\n",
      "|    position_penalty     | -123        |\n",
      "|    time                 | 203         |\n",
      "|    torque_penalty       | -60.8       |\n",
      "|    upright              | 76.9        |\n",
      "|    velocity_penalty     | -19.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 169         |\n",
      "|    ep_rew_mean          | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1757        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016320953 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00188     |\n",
      "|    loss                 | 4.45        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 256         |\n",
      "|    position_penalty     | -194        |\n",
      "|    time                 | 317         |\n",
      "|    torque_penalty       | -95.1       |\n",
      "|    upright              | 153         |\n",
      "|    velocity_penalty     | -23.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 174         |\n",
      "|    ep_rew_mean          | 212         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1758        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011903041 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00187     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.911       |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 94.7        |\n",
      "|    position_penalty     | -99.6       |\n",
      "|    time                 | 153         |\n",
      "|    torque_penalty       | -45.9       |\n",
      "|    upright              | 103         |\n",
      "|    velocity_penalty     | -15.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 179         |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1758        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011128988 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00187     |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 166         |\n",
      "|    position_penalty     | -126        |\n",
      "|    time                 | 243         |\n",
      "|    torque_penalty       | -72.8       |\n",
      "|    upright              | 111         |\n",
      "|    velocity_penalty     | -16         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 169         |\n",
      "|    ep_rew_mean          | 211         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1758        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015080449 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00186     |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 59.8        |\n",
      "|    position_penalty     | -63.3       |\n",
      "|    time                 | 125         |\n",
      "|    torque_penalty       | -37.5       |\n",
      "|    upright              | 94.9        |\n",
      "|    velocity_penalty     | -9.42       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 169         |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1758        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011444539 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00186     |\n",
      "|    loss                 | 4.19        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.897       |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 226         |\n",
      "|    position_penalty     | -195        |\n",
      "|    time                 | 333         |\n",
      "|    torque_penalty       | -99.7       |\n",
      "|    upright              | 193         |\n",
      "|    velocity_penalty     | -27.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 174         |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1759        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009808388 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00185     |\n",
      "|    loss                 | 5.54        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 160         |\n",
      "|    position_penalty     | -106        |\n",
      "|    time                 | 175         |\n",
      "|    torque_penalty       | -52.5       |\n",
      "|    upright              | 79.6        |\n",
      "|    velocity_penalty     | -19.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 246         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1759        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011208408 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00185     |\n",
      "|    loss                 | 7           |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.891       |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 49.8        |\n",
      "|    position_penalty     | -56.4       |\n",
      "|    time                 | 113         |\n",
      "|    torque_penalty       | -33.9       |\n",
      "|    upright              | 87.1        |\n",
      "|    velocity_penalty     | -9.13       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 256         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1760        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 474         |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010836239 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00184     |\n",
      "|    loss                 | 6.95        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 131         |\n",
      "|    position_penalty     | -108        |\n",
      "|    time                 | 170         |\n",
      "|    torque_penalty       | -51         |\n",
      "|    upright              | 101         |\n",
      "|    velocity_penalty     | -16.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | 226         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1761        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011158865 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00184     |\n",
      "|    loss                 | 6.39        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 173         |\n",
      "|    position_penalty     | -135        |\n",
      "|    time                 | 243         |\n",
      "|    torque_penalty       | -72.9       |\n",
      "|    upright              | 92.5        |\n",
      "|    velocity_penalty     | -17.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 253         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1761        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 502         |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014335188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00183     |\n",
      "|    loss                 | 6.08        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 41.3        |\n",
      "|    position_penalty     | -50.9       |\n",
      "|    time                 | 101         |\n",
      "|    torque_penalty       | -30.3       |\n",
      "|    upright              | 77.5        |\n",
      "|    velocity_penalty     | -7.94       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 177         |\n",
      "|    ep_rew_mean          | 232         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1762        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014514141 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.5       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00183     |\n",
      "|    loss                 | 6.23        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 220         |\n",
      "|    position_penalty     | -168        |\n",
      "|    time                 | 305         |\n",
      "|    torque_penalty       | -91.4       |\n",
      "|    upright              | 227         |\n",
      "|    velocity_penalty     | -21.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 256         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1762        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 529         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010916729 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.4       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00182     |\n",
      "|    loss                 | 6.02        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 118         |\n",
      "|    position_penalty     | -114        |\n",
      "|    time                 | 188         |\n",
      "|    torque_penalty       | -56.1       |\n",
      "|    upright              | 81.9        |\n",
      "|    velocity_penalty     | -12.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 252         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1763        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019573567 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00182     |\n",
      "|    loss                 | 5.47        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 103         |\n",
      "|    position_penalty     | -75.8       |\n",
      "|    time                 | 129         |\n",
      "|    torque_penalty       | -38.7       |\n",
      "|    upright              | 61.2        |\n",
      "|    velocity_penalty     | -11.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 240         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1763        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015037975 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00181     |\n",
      "|    loss                 | 7.56        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    std                  | 0.872       |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 46.8        |\n",
      "|    position_penalty     | -52.5       |\n",
      "|    time                 | 106         |\n",
      "|    torque_penalty       | -31.8       |\n",
      "|    upright              | 81.8        |\n",
      "|    velocity_penalty     | -8.51       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 253         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1763        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011697662 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.3       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00181     |\n",
      "|    loss                 | 7.34        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 155         |\n",
      "|    position_penalty     | -116        |\n",
      "|    time                 | 230         |\n",
      "|    torque_penalty       | -68.9       |\n",
      "|    upright              | 124         |\n",
      "|    velocity_penalty     | -13.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | 265         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1764        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 585         |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012128636 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.2       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0018      |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 115         |\n",
      "|    position_penalty     | -87.6       |\n",
      "|    time                 | 185         |\n",
      "|    torque_penalty       | -55.5       |\n",
      "|    upright              | 95.6        |\n",
      "|    velocity_penalty     | -11.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 258         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1764        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015794033 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.2       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0018      |\n",
      "|    loss                 | 6.63        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 91          |\n",
      "|    position_penalty     | -62.8       |\n",
      "|    time                 | 115         |\n",
      "|    torque_penalty       | -34.4       |\n",
      "|    upright              | 54.5        |\n",
      "|    velocity_penalty     | -9.87       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 202         |\n",
      "|    ep_rew_mean          | 269         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1765        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013203427 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.2       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00179     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 190         |\n",
      "|    position_penalty     | -132        |\n",
      "|    time                 | 214         |\n",
      "|    torque_penalty       | -64.2       |\n",
      "|    upright              | 77.9        |\n",
      "|    velocity_penalty     | -19         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 251         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1765        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014305624 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00179     |\n",
      "|    loss                 | 7.35        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 135        |\n",
      "|    position_penalty     | -106       |\n",
      "|    time                 | 188        |\n",
      "|    torque_penalty       | -56.4      |\n",
      "|    upright              | 86.8       |\n",
      "|    velocity_penalty     | -12.4      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 212        |\n",
      "|    ep_rew_mean          | 287        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1765       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 640        |\n",
      "|    total_timesteps      | 1130496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02241393 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -15.1      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.00178    |\n",
      "|    loss                 | 6.46       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 0.853      |\n",
      "|    value_loss           | 18         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 417         |\n",
      "|    position_penalty     | -256        |\n",
      "|    time                 | 518         |\n",
      "|    torque_penalty       | -155        |\n",
      "|    upright              | 374         |\n",
      "|    velocity_penalty     | -27.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 201         |\n",
      "|    ep_rew_mean          | 277         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1766        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011171865 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00178     |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 48.1        |\n",
      "|    position_penalty     | -55.6       |\n",
      "|    time                 | 112         |\n",
      "|    torque_penalty       | -33.5       |\n",
      "|    upright              | 95          |\n",
      "|    velocity_penalty     | -9.02       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 181         |\n",
      "|    ep_rew_mean          | 248         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1766        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016770042 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00177     |\n",
      "|    loss                 | 7.32        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.849       |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 76.7        |\n",
      "|    position_penalty     | -137        |\n",
      "|    time                 | 206         |\n",
      "|    torque_penalty       | -61.8       |\n",
      "|    upright              | 104         |\n",
      "|    velocity_penalty     | -20.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 190         |\n",
      "|    ep_rew_mean          | 250         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1766        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018405305 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00177     |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.844       |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 193         |\n",
      "|    position_penalty     | -144        |\n",
      "|    time                 | 243         |\n",
      "|    torque_penalty       | -72.8       |\n",
      "|    upright              | 91.8        |\n",
      "|    velocity_penalty     | -21.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 180         |\n",
      "|    ep_rew_mean          | 242         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1767        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014445708 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00177     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 77          |\n",
      "|    position_penalty     | -65.7       |\n",
      "|    time                 | 145         |\n",
      "|    torque_penalty       | -43.5       |\n",
      "|    upright              | 118         |\n",
      "|    velocity_penalty     | -9.48       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 204         |\n",
      "|    ep_rew_mean          | 276         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1767        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 709         |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013562699 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00176     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 126         |\n",
      "|    position_penalty     | -74.1       |\n",
      "|    time                 | 148         |\n",
      "|    torque_penalty       | -44.4       |\n",
      "|    upright              | 70.2        |\n",
      "|    velocity_penalty     | -11         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 201         |\n",
      "|    ep_rew_mean          | 269         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1767        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 722         |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013382102 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.9       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00176     |\n",
      "|    loss                 | 8.68        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 95.8        |\n",
      "|    position_penalty     | -64.1       |\n",
      "|    time                 | 166         |\n",
      "|    torque_penalty       | -49.7       |\n",
      "|    upright              | 116         |\n",
      "|    velocity_penalty     | -11.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 272         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1768        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 736         |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014277025 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.9       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00175     |\n",
      "|    loss                 | 8.93        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 233         |\n",
      "|    position_penalty     | -206        |\n",
      "|    time                 | 321         |\n",
      "|    torque_penalty       | -96.2       |\n",
      "|    upright              | 229         |\n",
      "|    velocity_penalty     | -22.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 208         |\n",
      "|    ep_rew_mean          | 282         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1768        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014756311 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.9       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00175     |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 0.839       |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 102         |\n",
      "|    position_penalty     | -77.7       |\n",
      "|    time                 | 157         |\n",
      "|    torque_penalty       | -47         |\n",
      "|    upright              | 62.8        |\n",
      "|    velocity_penalty     | -11.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | 274         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1768        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010584953 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.8       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00174     |\n",
      "|    loss                 | 7.89        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 78.9        |\n",
      "|    position_penalty     | -65.8       |\n",
      "|    time                 | 149         |\n",
      "|    torque_penalty       | -44.7       |\n",
      "|    upright              | 110         |\n",
      "|    velocity_penalty     | -9.97       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 210         |\n",
      "|    ep_rew_mean          | 286         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1769        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015542767 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.8       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00174     |\n",
      "|    loss                 | 7.25        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 93.1        |\n",
      "|    position_penalty     | -61         |\n",
      "|    time                 | 149         |\n",
      "|    torque_penalty       | -44.7       |\n",
      "|    upright              | 82.4        |\n",
      "|    velocity_penalty     | -10.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 226         |\n",
      "|    ep_rew_mean          | 306         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1769        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015326306 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00173     |\n",
      "|    loss                 | 6.91        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.829       |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 70.9        |\n",
      "|    position_penalty     | -45.1       |\n",
      "|    time                 | 125         |\n",
      "|    torque_penalty       | -37.5       |\n",
      "|    upright              | 59.2        |\n",
      "|    velocity_penalty     | -10         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 205         |\n",
      "|    ep_rew_mean          | 284         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1769        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012683652 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.7       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00173     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 171         |\n",
      "|    position_penalty     | -154        |\n",
      "|    time                 | 247         |\n",
      "|    torque_penalty       | -74.1       |\n",
      "|    upright              | 121         |\n",
      "|    velocity_penalty     | -21.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 223         |\n",
      "|    ep_rew_mean          | 304         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1769        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 819         |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018975891 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00172     |\n",
      "|    loss                 | 5.88        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 67.5        |\n",
      "|    position_penalty     | -58.6       |\n",
      "|    time                 | 132         |\n",
      "|    torque_penalty       | -39.6       |\n",
      "|    upright              | 112         |\n",
      "|    velocity_penalty     | -9.48       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 211         |\n",
      "|    ep_rew_mean          | 296         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1770        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 832         |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014402568 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00172     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 88.8        |\n",
      "|    position_penalty     | -53.7       |\n",
      "|    time                 | 125         |\n",
      "|    torque_penalty       | -37.5       |\n",
      "|    upright              | 65.8        |\n",
      "|    velocity_penalty     | -10         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 220         |\n",
      "|    ep_rew_mean          | 322         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1770        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 846         |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013292551 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.6       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00171     |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 282         |\n",
      "|    position_penalty     | -194        |\n",
      "|    time                 | 384         |\n",
      "|    torque_penalty       | -115        |\n",
      "|    upright              | 236         |\n",
      "|    velocity_penalty     | -24.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 213         |\n",
      "|    ep_rew_mean          | 305         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1770        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 860         |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021752678 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.6       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00171     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.821       |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 156         |\n",
      "|    position_penalty     | -163        |\n",
      "|    time                 | 251         |\n",
      "|    torque_penalty       | -75.2       |\n",
      "|    upright              | 107         |\n",
      "|    velocity_penalty     | -25         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 222         |\n",
      "|    ep_rew_mean          | 315         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1771        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018040175 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.6       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0017      |\n",
      "|    loss                 | 7.59        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.818       |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 214         |\n",
      "|    position_penalty     | -127        |\n",
      "|    time                 | 303         |\n",
      "|    torque_penalty       | -90.8       |\n",
      "|    upright              | 184         |\n",
      "|    velocity_penalty     | -15.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 233         |\n",
      "|    ep_rew_mean          | 340         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1771        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 887         |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014350601 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.5       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0017      |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 172        |\n",
      "|    position_penalty     | -89.6      |\n",
      "|    time                 | 251        |\n",
      "|    torque_penalty       | -75.3      |\n",
      "|    upright              | 185        |\n",
      "|    velocity_penalty     | -11.2      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 221        |\n",
      "|    ep_rew_mean          | 300        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1772       |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 901        |\n",
      "|    total_timesteps      | 1597440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01401411 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -14.5      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00169    |\n",
      "|    loss                 | 7.07       |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 0.814      |\n",
      "|    value_loss           | 20.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 87.2       |\n",
      "|    position_penalty     | -64.9      |\n",
      "|    time                 | 159        |\n",
      "|    torque_penalty       | -47.5      |\n",
      "|    upright              | 117        |\n",
      "|    velocity_penalty     | -9.15      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 225        |\n",
      "|    ep_rew_mean          | 337        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1772       |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 915        |\n",
      "|    total_timesteps      | 1622016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02500534 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -14.4      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.00169    |\n",
      "|    loss                 | 6.48       |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 0.811      |\n",
      "|    value_loss           | 20.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 61.3        |\n",
      "|    position_penalty     | -53.3       |\n",
      "|    time                 | 122         |\n",
      "|    torque_penalty       | -36.6       |\n",
      "|    upright              | 96.1        |\n",
      "|    velocity_penalty     | -8.98       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 203         |\n",
      "|    ep_rew_mean          | 284         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1772        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 928         |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019903421 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.4       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00168     |\n",
      "|    loss                 | 6.23        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.809       |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| reward_components/      |           |\n",
      "|    height               | 112       |\n",
      "|    position_penalty     | -77.4     |\n",
      "|    time                 | 184       |\n",
      "|    torque_penalty       | -55       |\n",
      "|    upright              | 136       |\n",
      "|    velocity_penalty     | -13.1     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 215       |\n",
      "|    ep_rew_mean          | 310       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1772      |\n",
      "|    iterations           | 68        |\n",
      "|    time_elapsed         | 942       |\n",
      "|    total_timesteps      | 1671168   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0178072 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -14.4     |\n",
      "|    explained_variance   | 0.994     |\n",
      "|    learning_rate        | 0.00168   |\n",
      "|    loss                 | 6.04      |\n",
      "|    n_updates            | 670       |\n",
      "|    policy_gradient_loss | -0.0156   |\n",
      "|    std                  | 0.807     |\n",
      "|    value_loss           | 20.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 54          |\n",
      "|    position_penalty     | -50.7       |\n",
      "|    time                 | 116         |\n",
      "|    torque_penalty       | -34.8       |\n",
      "|    upright              | 89.3        |\n",
      "|    velocity_penalty     | -8.12       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 224         |\n",
      "|    ep_rew_mean          | 324         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1772        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 956         |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020599285 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.3       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00167     |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 0.804       |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 63.9        |\n",
      "|    position_penalty     | -55.9       |\n",
      "|    time                 | 123         |\n",
      "|    torque_penalty       | -36.8       |\n",
      "|    upright              | 78.6        |\n",
      "|    velocity_penalty     | -9.1        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 209         |\n",
      "|    ep_rew_mean          | 311         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1772        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 970         |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017470628 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.3       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00167     |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 0.801       |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 98          |\n",
      "|    position_penalty     | -68.2       |\n",
      "|    time                 | 167         |\n",
      "|    torque_penalty       | -50         |\n",
      "|    upright              | 126         |\n",
      "|    velocity_penalty     | -10.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 223         |\n",
      "|    ep_rew_mean          | 330         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1773        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 983         |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018836493 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.2       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00166     |\n",
      "|    loss                 | 6.35        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 0.796       |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 285         |\n",
      "|    position_penalty     | -138        |\n",
      "|    time                 | 377         |\n",
      "|    torque_penalty       | -113        |\n",
      "|    upright              | 307         |\n",
      "|    velocity_penalty     | -16.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 229         |\n",
      "|    ep_rew_mean          | 356         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1773        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 997         |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022218185 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.1       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00166     |\n",
      "|    loss                 | 6.55        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 0.792       |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 321         |\n",
      "|    position_penalty     | -178        |\n",
      "|    time                 | 439         |\n",
      "|    torque_penalty       | -131        |\n",
      "|    upright              | 185         |\n",
      "|    velocity_penalty     | -23.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 237         |\n",
      "|    ep_rew_mean          | 359         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1774        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1011        |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018414356 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.1       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00165     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 0.789       |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 111         |\n",
      "|    position_penalty     | -66.8       |\n",
      "|    time                 | 183         |\n",
      "|    torque_penalty       | -54.8       |\n",
      "|    upright              | 146         |\n",
      "|    velocity_penalty     | -9.42       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 228         |\n",
      "|    ep_rew_mean          | 342         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1774        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1024        |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017730275 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.1       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00165     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.787       |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 80.9       |\n",
      "|    position_penalty     | -54.8      |\n",
      "|    time                 | 148        |\n",
      "|    torque_penalty       | -44.3      |\n",
      "|    upright              | 116        |\n",
      "|    velocity_penalty     | -9.11      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 229        |\n",
      "|    ep_rew_mean          | 355        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1774       |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 1038       |\n",
      "|    total_timesteps      | 1843200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02051524 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -14        |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00165    |\n",
      "|    loss                 | 7.26       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 0.787      |\n",
      "|    value_loss           | 22         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 144         |\n",
      "|    position_penalty     | -87.1       |\n",
      "|    time                 | 229         |\n",
      "|    torque_penalty       | -68.6       |\n",
      "|    upright              | 184         |\n",
      "|    velocity_penalty     | -10.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 218         |\n",
      "|    ep_rew_mean          | 322         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1774        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017370079 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00164     |\n",
      "|    loss                 | 6.53        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 0.785       |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 98.3       |\n",
      "|    position_penalty     | -60.4      |\n",
      "|    time                 | 173        |\n",
      "|    torque_penalty       | -51.9      |\n",
      "|    upright              | 131        |\n",
      "|    velocity_penalty     | -9.69      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 233        |\n",
      "|    ep_rew_mean          | 348        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1775       |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 1066       |\n",
      "|    total_timesteps      | 1892352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01957383 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -14        |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00164    |\n",
      "|    loss                 | 6.3        |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    std                  | 0.782      |\n",
      "|    value_loss           | 20         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 272         |\n",
      "|    position_penalty     | -184        |\n",
      "|    time                 | 362         |\n",
      "|    torque_penalty       | -108        |\n",
      "|    upright              | 291         |\n",
      "|    velocity_penalty     | -26.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 268         |\n",
      "|    ep_rew_mean          | 413         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1775        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1079        |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022906018 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00163     |\n",
      "|    loss                 | 8.17        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.779       |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 124         |\n",
      "|    position_penalty     | -57.9       |\n",
      "|    time                 | 150         |\n",
      "|    torque_penalty       | -45         |\n",
      "|    upright              | 84.7        |\n",
      "|    velocity_penalty     | -9.42       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 243         |\n",
      "|    ep_rew_mean          | 370         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1775        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1093        |\n",
      "|    total_timesteps      | 1941504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016550569 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00163     |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 0.779       |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 89.8       |\n",
      "|    position_penalty     | -75        |\n",
      "|    time                 | 149        |\n",
      "|    torque_penalty       | -44.4      |\n",
      "|    upright              | 90.2       |\n",
      "|    velocity_penalty     | -12        |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 234        |\n",
      "|    ep_rew_mean          | 350        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1776       |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 1107       |\n",
      "|    total_timesteps      | 1966080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01899856 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.9      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00162    |\n",
      "|    loss                 | 7.66       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    std                  | 0.776      |\n",
      "|    value_loss           | 22.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 119        |\n",
      "|    position_penalty     | -68        |\n",
      "|    time                 | 188        |\n",
      "|    torque_penalty       | -56.3      |\n",
      "|    upright              | 126        |\n",
      "|    velocity_penalty     | -10.7      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 259        |\n",
      "|    ep_rew_mean          | 405        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1776       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 1120       |\n",
      "|    total_timesteps      | 1990656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01707884 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.8      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.00162    |\n",
      "|    loss                 | 8.08       |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 0.774      |\n",
      "|    value_loss           | 24.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 104         |\n",
      "|    position_penalty     | -88.4       |\n",
      "|    time                 | 170         |\n",
      "|    torque_penalty       | -50.7       |\n",
      "|    upright              | 93.5        |\n",
      "|    velocity_penalty     | -13.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 228         |\n",
      "|    ep_rew_mean          | 355         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1776        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1134        |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027368784 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.8       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00161     |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.771       |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 131         |\n",
      "|    position_penalty     | -93.3       |\n",
      "|    time                 | 179         |\n",
      "|    torque_penalty       | -53.5       |\n",
      "|    upright              | 81.3        |\n",
      "|    velocity_penalty     | -13.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 217         |\n",
      "|    ep_rew_mean          | 336         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1776        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023590408 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.8       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00161     |\n",
      "|    loss                 | 6.4         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.769       |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 218         |\n",
      "|    position_penalty     | -131        |\n",
      "|    time                 | 301         |\n",
      "|    torque_penalty       | -89.9       |\n",
      "|    upright              | 219         |\n",
      "|    velocity_penalty     | -20.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 213         |\n",
      "|    ep_rew_mean          | 324         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1776        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1161        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024760662 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.7       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0016      |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 0.766       |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 65.7       |\n",
      "|    position_penalty     | -42.9      |\n",
      "|    time                 | 125        |\n",
      "|    torque_penalty       | -37.4      |\n",
      "|    upright              | 84.7       |\n",
      "|    velocity_penalty     | -8.85      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 253        |\n",
      "|    ep_rew_mean          | 396        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1777       |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 1175       |\n",
      "|    total_timesteps      | 2088960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02092697 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.7      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0016     |\n",
      "|    loss                 | 6.67       |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 0.762      |\n",
      "|    value_loss           | 19.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 159         |\n",
      "|    position_penalty     | -98.2       |\n",
      "|    time                 | 236         |\n",
      "|    torque_penalty       | -70.7       |\n",
      "|    upright              | 162         |\n",
      "|    velocity_penalty     | -14.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 253         |\n",
      "|    ep_rew_mean          | 398         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1777        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018400786 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.6       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00159     |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.76        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 172         |\n",
      "|    position_penalty     | -59.1       |\n",
      "|    time                 | 210         |\n",
      "|    torque_penalty       | -62.9       |\n",
      "|    upright              | 105         |\n",
      "|    velocity_penalty     | -10.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 248         |\n",
      "|    ep_rew_mean          | 384         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1777        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1202        |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025451338 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.6       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00159     |\n",
      "|    loss                 | 7.49        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.76        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 128         |\n",
      "|    position_penalty     | -78.2       |\n",
      "|    time                 | 174         |\n",
      "|    torque_penalty       | -51.9       |\n",
      "|    upright              | 92.1        |\n",
      "|    velocity_penalty     | -11.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 250         |\n",
      "|    ep_rew_mean          | 391         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1778        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1216        |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026793083 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.6       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00158     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.758       |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 70.7        |\n",
      "|    position_penalty     | -36.8       |\n",
      "|    time                 | 132         |\n",
      "|    torque_penalty       | -39.6       |\n",
      "|    upright              | 79.6        |\n",
      "|    velocity_penalty     | -9.94       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 273         |\n",
      "|    ep_rew_mean          | 433         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1778        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1229        |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016701838 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.5       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00158     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.756       |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 205        |\n",
      "|    position_penalty     | -185       |\n",
      "|    time                 | 345        |\n",
      "|    torque_penalty       | -103       |\n",
      "|    upright              | 202        |\n",
      "|    velocity_penalty     | -22.3      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 270        |\n",
      "|    ep_rew_mean          | 424        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1778       |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 1243       |\n",
      "|    total_timesteps      | 2211840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01666043 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.5      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00157    |\n",
      "|    loss                 | 9.07       |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 0.754      |\n",
      "|    value_loss           | 29.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 219         |\n",
      "|    position_penalty     | -178        |\n",
      "|    time                 | 325         |\n",
      "|    torque_penalty       | -97.4       |\n",
      "|    upright              | 196         |\n",
      "|    velocity_penalty     | -22.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 529         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1778        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1257        |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015181976 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.5       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00157     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 0.752       |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 216        |\n",
      "|    position_penalty     | -114       |\n",
      "|    time                 | 289        |\n",
      "|    torque_penalty       | -86.5      |\n",
      "|    upright              | 169        |\n",
      "|    velocity_penalty     | -17.3      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 241        |\n",
      "|    ep_rew_mean          | 374        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1779       |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 1270       |\n",
      "|    total_timesteps      | 2260992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01498399 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.4      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00156    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 0.749      |\n",
      "|    value_loss           | 37.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 62.9        |\n",
      "|    position_penalty     | -41.4       |\n",
      "|    time                 | 123         |\n",
      "|    torque_penalty       | -36.8       |\n",
      "|    upright              | 76.9        |\n",
      "|    velocity_penalty     | -9.27       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 287         |\n",
      "|    ep_rew_mean          | 453         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1779        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1284        |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030351238 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.4       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00156     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 0.745       |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 58.5        |\n",
      "|    position_penalty     | -43.6       |\n",
      "|    time                 | 118         |\n",
      "|    torque_penalty       | -35.4       |\n",
      "|    upright              | 81.7        |\n",
      "|    velocity_penalty     | -8.46       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 276         |\n",
      "|    ep_rew_mean          | 445         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1779        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019776335 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.4       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00155     |\n",
      "|    loss                 | 8.45        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.745       |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 135         |\n",
      "|    position_penalty     | -55.4       |\n",
      "|    time                 | 220         |\n",
      "|    torque_penalty       | -65.8       |\n",
      "|    upright              | 125         |\n",
      "|    velocity_penalty     | -10.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 284         |\n",
      "|    ep_rew_mean          | 461         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1779        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1311        |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015113346 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00155     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 0.744       |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 98.7        |\n",
      "|    position_penalty     | -42.9       |\n",
      "|    time                 | 133         |\n",
      "|    torque_penalty       | -39.9       |\n",
      "|    upright              | 74.6        |\n",
      "|    velocity_penalty     | -9.77       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 233         |\n",
      "|    ep_rew_mean          | 365         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1780        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015650146 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00154     |\n",
      "|    loss                 | 9.09        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 0.742       |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 208         |\n",
      "|    position_penalty     | -82.3       |\n",
      "|    time                 | 286         |\n",
      "|    torque_penalty       | -85.6       |\n",
      "|    upright              | 206         |\n",
      "|    velocity_penalty     | -14         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 454         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1780        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1338        |\n",
      "|    total_timesteps      | 2383872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016802264 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00154     |\n",
      "|    loss                 | 8.18        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.741       |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 54.4        |\n",
      "|    position_penalty     | -44.1       |\n",
      "|    time                 | 113         |\n",
      "|    torque_penalty       | -33.9       |\n",
      "|    upright              | 83.3        |\n",
      "|    velocity_penalty     | -8.49       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 255         |\n",
      "|    ep_rew_mean          | 404         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1780        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1352        |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017821025 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00154     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 0.739       |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 168         |\n",
      "|    position_penalty     | -146        |\n",
      "|    time                 | 228         |\n",
      "|    torque_penalty       | -68.1       |\n",
      "|    upright              | 109         |\n",
      "|    velocity_penalty     | -26.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 257         |\n",
      "|    ep_rew_mean          | 411         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1780        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1366        |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019954516 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00153     |\n",
      "|    loss                 | 9.85        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 0.736       |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 215         |\n",
      "|    position_penalty     | -85         |\n",
      "|    time                 | 302         |\n",
      "|    torque_penalty       | -90.5       |\n",
      "|    upright              | 204         |\n",
      "|    velocity_penalty     | -12.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 262         |\n",
      "|    ep_rew_mean          | 424         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1780        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1380        |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020850042 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00153     |\n",
      "|    loss                 | 8.78        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.735       |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 105         |\n",
      "|    position_penalty     | -37.6       |\n",
      "|    time                 | 173         |\n",
      "|    torque_penalty       | -51.7       |\n",
      "|    upright              | 81.9        |\n",
      "|    velocity_penalty     | -10.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 442         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1781        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1393        |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018980043 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00152     |\n",
      "|    loss                 | 9.96        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.733       |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 597         |\n",
      "|    position_penalty     | -209        |\n",
      "|    time                 | 698         |\n",
      "|    torque_penalty       | -209        |\n",
      "|    upright              | 578         |\n",
      "|    velocity_penalty     | -23.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 268         |\n",
      "|    ep_rew_mean          | 438         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1781        |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1407        |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020152053 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00152     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 0.732       |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 96.2        |\n",
      "|    position_penalty     | -47.2       |\n",
      "|    time                 | 163         |\n",
      "|    torque_penalty       | -48.8       |\n",
      "|    upright              | 113         |\n",
      "|    velocity_penalty     | -9.88       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 252         |\n",
      "|    ep_rew_mean          | 413         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1781        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1421        |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017494539 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00151     |\n",
      "|    loss                 | 8.37        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.729       |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 102         |\n",
      "|    position_penalty     | -81.5       |\n",
      "|    time                 | 164         |\n",
      "|    torque_penalty       | -49         |\n",
      "|    upright              | 92          |\n",
      "|    velocity_penalty     | -11.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 268         |\n",
      "|    ep_rew_mean          | 423         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1781        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1434        |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016985008 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00151     |\n",
      "|    loss                 | 9.33        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 0.727       |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 133         |\n",
      "|    position_penalty     | -98.3       |\n",
      "|    time                 | 198         |\n",
      "|    torque_penalty       | -59.1       |\n",
      "|    upright              | 128         |\n",
      "|    velocity_penalty     | -13.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 450         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1781        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1448        |\n",
      "|    total_timesteps      | 2580480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016036745 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0015      |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.727       |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 97.7        |\n",
      "|    position_penalty     | -81.9       |\n",
      "|    time                 | 157         |\n",
      "|    torque_penalty       | -46.6       |\n",
      "|    upright              | 97.6        |\n",
      "|    velocity_penalty     | -10.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 298         |\n",
      "|    ep_rew_mean          | 497         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1782        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1461        |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019054718 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0015      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.726       |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 144        |\n",
      "|    position_penalty     | -83.9      |\n",
      "|    time                 | 219        |\n",
      "|    torque_penalty       | -65.5      |\n",
      "|    upright              | 160        |\n",
      "|    velocity_penalty     | -15        |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 319        |\n",
      "|    ep_rew_mean          | 538        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1782       |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 1475       |\n",
      "|    total_timesteps      | 2629632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01463713 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13        |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00149    |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 0.725      |\n",
      "|    value_loss           | 40.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 55.3        |\n",
      "|    position_penalty     | -38.1       |\n",
      "|    time                 | 113         |\n",
      "|    torque_penalty       | -33.9       |\n",
      "|    upright              | 72.8        |\n",
      "|    velocity_penalty     | -8.39       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 296         |\n",
      "|    ep_rew_mean          | 501         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1782        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 1489        |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016782554 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00149     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 0.725       |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 118         |\n",
      "|    position_penalty     | -70.9       |\n",
      "|    time                 | 157         |\n",
      "|    torque_penalty       | -47         |\n",
      "|    upright              | 88.4        |\n",
      "|    velocity_penalty     | -11.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 274         |\n",
      "|    ep_rew_mean          | 460         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1782        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1502        |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016982278 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00148     |\n",
      "|    loss                 | 8.67        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.724       |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 194        |\n",
      "|    position_penalty     | -175       |\n",
      "|    time                 | 274        |\n",
      "|    torque_penalty       | -81.9      |\n",
      "|    upright              | 146        |\n",
      "|    velocity_penalty     | -27.5      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 274        |\n",
      "|    ep_rew_mean          | 461        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1782       |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 1516       |\n",
      "|    total_timesteps      | 2703360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01866314 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13        |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00148    |\n",
      "|    loss                 | 9.81       |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    std                  | 0.722      |\n",
      "|    value_loss           | 30.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 187         |\n",
      "|    position_penalty     | -146        |\n",
      "|    time                 | 252         |\n",
      "|    torque_penalty       | -75.3       |\n",
      "|    upright              | 163         |\n",
      "|    velocity_penalty     | -20.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 298         |\n",
      "|    ep_rew_mean          | 505         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1783        |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 1529        |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022863572 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00147     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.721       |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 91          |\n",
      "|    position_penalty     | -35.2       |\n",
      "|    time                 | 149         |\n",
      "|    torque_penalty       | -44.6       |\n",
      "|    upright              | 60.9        |\n",
      "|    velocity_penalty     | -11         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 282         |\n",
      "|    ep_rew_mean          | 479         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1783        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 1543        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019297881 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00147     |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.718       |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 67.9        |\n",
      "|    position_penalty     | -45.8       |\n",
      "|    time                 | 128         |\n",
      "|    torque_penalty       | -38.4       |\n",
      "|    upright              | 79.8        |\n",
      "|    velocity_penalty     | -8.84       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 304         |\n",
      "|    ep_rew_mean          | 509         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1783        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 1557        |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024387946 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00146     |\n",
      "|    loss                 | 9.47        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.717       |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 79.4        |\n",
      "|    position_penalty     | -47.8       |\n",
      "|    time                 | 145         |\n",
      "|    torque_penalty       | -43.4       |\n",
      "|    upright              | 102         |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | 583         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1783        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 1570        |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015159688 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00146     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.716       |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 207         |\n",
      "|    position_penalty     | -130        |\n",
      "|    time                 | 272         |\n",
      "|    torque_penalty       | -81.3       |\n",
      "|    upright              | 182         |\n",
      "|    velocity_penalty     | -18.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 316         |\n",
      "|    ep_rew_mean          | 537         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1783        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 1584        |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016102724 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00145     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.715       |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 100        |\n",
      "|    position_penalty     | -35.3      |\n",
      "|    time                 | 162        |\n",
      "|    torque_penalty       | -48.6      |\n",
      "|    upright              | 66.8       |\n",
      "|    velocity_penalty     | -10.5      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 329        |\n",
      "|    ep_rew_mean          | 558        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1784       |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 1597       |\n",
      "|    total_timesteps      | 2850816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02182082 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.8      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00145    |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 1150       |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 0.713      |\n",
      "|    value_loss           | 43.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 57.6        |\n",
      "|    position_penalty     | -47.7       |\n",
      "|    time                 | 117         |\n",
      "|    torque_penalty       | -35.1       |\n",
      "|    upright              | 69.4        |\n",
      "|    velocity_penalty     | -9.34       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | 452         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1784        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 1611        |\n",
      "|    total_timesteps      | 2875392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020337531 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00144     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 0.711       |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 220         |\n",
      "|    position_penalty     | -134        |\n",
      "|    time                 | 286         |\n",
      "|    torque_penalty       | -85.4       |\n",
      "|    upright              | 207         |\n",
      "|    velocity_penalty     | -17.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 471         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1784        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 1625        |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016519519 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00144     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.709       |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 1.13e+03    |\n",
      "|    position_penalty     | -231        |\n",
      "|    time                 | 1.22e+03    |\n",
      "|    torque_penalty       | -367        |\n",
      "|    upright              | 1.03e+03    |\n",
      "|    velocity_penalty     | -32.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 534         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1784        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 1638        |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018919645 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00143     |\n",
      "|    loss                 | 9.38        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 0.707       |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 79.5       |\n",
      "|    position_penalty     | -33.9      |\n",
      "|    time                 | 136        |\n",
      "|    torque_penalty       | -40.5      |\n",
      "|    upright              | 80.5       |\n",
      "|    velocity_penalty     | -9.36      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 308        |\n",
      "|    ep_rew_mean          | 532        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1784       |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 1652       |\n",
      "|    total_timesteps      | 2949120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02446528 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.7      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.00143    |\n",
      "|    loss                 | 10.3       |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 0.705      |\n",
      "|    value_loss           | 32.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 381        |\n",
      "|    position_penalty     | -98.7      |\n",
      "|    time                 | 470        |\n",
      "|    torque_penalty       | -141       |\n",
      "|    upright              | 346        |\n",
      "|    velocity_penalty     | -17.2      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 301        |\n",
      "|    ep_rew_mean          | 513        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1785       |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 1665       |\n",
      "|    total_timesteps      | 2973696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01822771 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.00142    |\n",
      "|    loss                 | 21.7       |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    std                  | 0.705      |\n",
      "|    value_loss           | 82.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 304         |\n",
      "|    position_penalty     | -232        |\n",
      "|    time                 | 394         |\n",
      "|    torque_penalty       | -118        |\n",
      "|    upright              | 209         |\n",
      "|    velocity_penalty     | -31.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 391         |\n",
      "|    ep_rew_mean          | 731         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1785        |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 1679        |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029263036 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.00142     |\n",
      "|    loss                 | 7.82        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 231         |\n",
      "|    position_penalty     | -159        |\n",
      "|    time                 | 314         |\n",
      "|    torque_penalty       | -93.7       |\n",
      "|    upright              | 231         |\n",
      "|    velocity_penalty     | -18.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 488         |\n",
      "|    ep_rew_mean          | 969         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1785        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 1692        |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018679442 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00142     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    std                  | 0.707       |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 113        |\n",
      "|    position_penalty     | -43.8      |\n",
      "|    time                 | 189        |\n",
      "|    torque_penalty       | -56.6      |\n",
      "|    upright              | 115        |\n",
      "|    velocity_penalty     | -9.72      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 542        |\n",
      "|    ep_rew_mean          | 1.09e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1786       |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 1705       |\n",
      "|    total_timesteps      | 3047424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01777052 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.00141    |\n",
      "|    loss                 | 64.4       |\n",
      "|    n_updates            | 1230       |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    std                  | 0.705      |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 91.8        |\n",
      "|    position_penalty     | -68.2       |\n",
      "|    time                 | 146         |\n",
      "|    torque_penalty       | -43.6       |\n",
      "|    upright              | 82.2        |\n",
      "|    velocity_penalty     | -11.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 724         |\n",
      "|    ep_rew_mean          | 1.56e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1786        |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 1719        |\n",
      "|    total_timesteps      | 3072000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029158855 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00141     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 209         |\n",
      "|    position_penalty     | -60.7       |\n",
      "|    time                 | 309         |\n",
      "|    torque_penalty       | -92.3       |\n",
      "|    upright              | 169         |\n",
      "|    velocity_penalty     | -11.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 833         |\n",
      "|    ep_rew_mean          | 1.82e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1787        |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 3096576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017938757 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0014      |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 157         |\n",
      "|    position_penalty     | -43.7       |\n",
      "|    time                 | 186         |\n",
      "|    torque_penalty       | -55.7       |\n",
      "|    upright              | 105         |\n",
      "|    velocity_penalty     | -9.46       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | 1.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1787        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 1746        |\n",
      "|    total_timesteps      | 3121152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014380969 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0014      |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 62          |\n",
      "|    position_penalty     | -36.7       |\n",
      "|    time                 | 120         |\n",
      "|    torque_penalty       | -35.7       |\n",
      "|    upright              | 70.6        |\n",
      "|    velocity_penalty     | -9.06       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 622         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1787        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 1759        |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014042333 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.00139     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 67.8        |\n",
      "|    position_penalty     | -33         |\n",
      "|    time                 | 124         |\n",
      "|    torque_penalty       | -37.2       |\n",
      "|    upright              | 73.3        |\n",
      "|    velocity_penalty     | -8.74       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | 1.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1788        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 1772        |\n",
      "|    total_timesteps      | 3170304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019460453 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00139     |\n",
      "|    loss                 | 85.7        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 73.6        |\n",
      "|    position_penalty     | -25.7       |\n",
      "|    time                 | 131         |\n",
      "|    torque_penalty       | -39.2       |\n",
      "|    upright              | 49.9        |\n",
      "|    velocity_penalty     | -9.02       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 609         |\n",
      "|    ep_rew_mean          | 1.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1788        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 1786        |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012488508 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00138     |\n",
      "|    loss                 | 71.4        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 170         |\n",
      "|    position_penalty     | -141        |\n",
      "|    time                 | 242         |\n",
      "|    torque_penalty       | -72.2       |\n",
      "|    upright              | 138         |\n",
      "|    velocity_penalty     | -20.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 624         |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1788        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 1799        |\n",
      "|    total_timesteps      | 3219456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022314047 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.00138     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 332        |\n",
      "|    position_penalty     | -349       |\n",
      "|    time                 | 536        |\n",
      "|    torque_penalty       | -160       |\n",
      "|    upright              | 182        |\n",
      "|    velocity_penalty     | -51.8      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 696        |\n",
      "|    ep_rew_mean          | 1.5e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1788       |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 1813       |\n",
      "|    total_timesteps      | 3244032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02144956 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.00137    |\n",
      "|    loss                 | 49.4       |\n",
      "|    n_updates            | 1310       |\n",
      "|    policy_gradient_loss | -0.00834   |\n",
      "|    std                  | 0.705      |\n",
      "|    value_loss           | 158        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 84.3        |\n",
      "|    position_penalty     | -52.6       |\n",
      "|    time                 | 127         |\n",
      "|    torque_penalty       | -37.7       |\n",
      "|    upright              | 59.2        |\n",
      "|    velocity_penalty     | -9.67       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 548         |\n",
      "|    ep_rew_mean          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1789        |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 1826        |\n",
      "|    total_timesteps      | 3268608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015888795 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.00137     |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 87.8        |\n",
      "|    position_penalty     | -42.9       |\n",
      "|    time                 | 118         |\n",
      "|    torque_penalty       | -35.2       |\n",
      "|    upright              | 59.4        |\n",
      "|    velocity_penalty     | -9.7        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 627         |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1789        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 1840        |\n",
      "|    total_timesteps      | 3293184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026052872 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.00136     |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| reward_components/      |           |\n",
      "|    height               | 431       |\n",
      "|    position_penalty     | -165      |\n",
      "|    time                 | 521       |\n",
      "|    torque_penalty       | -156      |\n",
      "|    upright              | 401       |\n",
      "|    velocity_penalty     | -27.2     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | 1.2e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1789      |\n",
      "|    iterations           | 135       |\n",
      "|    time_elapsed         | 1854      |\n",
      "|    total_timesteps      | 3317760   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0150131 |\n",
      "|    clip_fraction        | 0.289     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -12.6     |\n",
      "|    explained_variance   | 0.989     |\n",
      "|    learning_rate        | 0.00136   |\n",
      "|    loss                 | 122       |\n",
      "|    n_updates            | 1340      |\n",
      "|    policy_gradient_loss | -0.00548  |\n",
      "|    std                  | 0.705     |\n",
      "|    value_loss           | 274       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 1.9e+03    |\n",
      "|    position_penalty     | -487       |\n",
      "|    time                 | 2.02e+03   |\n",
      "|    torque_penalty       | -604       |\n",
      "|    upright              | 1.81e+03   |\n",
      "|    velocity_penalty     | -62.1      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 728        |\n",
      "|    ep_rew_mean          | 1.58e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1789       |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 1867       |\n",
      "|    total_timesteps      | 3342336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01893331 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.00135    |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 0.706      |\n",
      "|    value_loss           | 82.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 131         |\n",
      "|    position_penalty     | -65.3       |\n",
      "|    time                 | 197         |\n",
      "|    torque_penalty       | -58.8       |\n",
      "|    upright              | 124         |\n",
      "|    velocity_penalty     | -12.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 636         |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1789        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 1881        |\n",
      "|    total_timesteps      | 3366912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020691877 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.00135     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -1e+03      |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.7e+03     |\n",
      "|    velocity_penalty     | -111        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 742         |\n",
      "|    ep_rew_mean          | 1.61e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1790        |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 1894        |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019695617 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00134     |\n",
      "|    loss                 | 90.5        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 83.9       |\n",
      "|    position_penalty     | -44.5      |\n",
      "|    time                 | 141        |\n",
      "|    torque_penalty       | -42.3      |\n",
      "|    upright              | 84.9       |\n",
      "|    velocity_penalty     | -9.27      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 836        |\n",
      "|    ep_rew_mean          | 1.84e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1790       |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 1907       |\n",
      "|    total_timesteps      | 3416064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02291067 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.7      |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.00134    |\n",
      "|    loss                 | 79.8       |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.00826   |\n",
      "|    std                  | 0.708      |\n",
      "|    value_loss           | 225        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 183         |\n",
      "|    position_penalty     | -64.2       |\n",
      "|    time                 | 265         |\n",
      "|    torque_penalty       | -79.4       |\n",
      "|    upright              | 177         |\n",
      "|    velocity_penalty     | -11.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 950         |\n",
      "|    ep_rew_mean          | 2.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1790        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 1921        |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032119412 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.00133     |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    std                  | 0.709       |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| reward_components/      |           |\n",
      "|    height               | 109       |\n",
      "|    position_penalty     | -49.7     |\n",
      "|    time                 | 180       |\n",
      "|    torque_penalty       | -53.8     |\n",
      "|    upright              | 122       |\n",
      "|    velocity_penalty     | -10.1     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 910       |\n",
      "|    ep_rew_mean          | 2.02e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1791      |\n",
      "|    iterations           | 141       |\n",
      "|    time_elapsed         | 1934      |\n",
      "|    total_timesteps      | 3465216   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0199466 |\n",
      "|    clip_fraction        | 0.323     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -12.7     |\n",
      "|    explained_variance   | 0.972     |\n",
      "|    learning_rate        | 0.00133   |\n",
      "|    loss                 | 248       |\n",
      "|    n_updates            | 1400      |\n",
      "|    policy_gradient_loss | -0.00694  |\n",
      "|    std                  | 0.713     |\n",
      "|    value_loss           | 533       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 95.8        |\n",
      "|    position_penalty     | -52.3       |\n",
      "|    time                 | 154         |\n",
      "|    torque_penalty       | -46         |\n",
      "|    upright              | 77.9        |\n",
      "|    velocity_penalty     | -12.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | 1.46e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1790        |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 1948        |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014169498 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.00132     |\n",
      "|    loss                 | 80.7        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    std                  | 0.711       |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.18e+03    |\n",
      "|    position_penalty     | -836        |\n",
      "|    time                 | 4.27e+03    |\n",
      "|    torque_penalty       | -1.28e+03   |\n",
      "|    upright              | 3.97e+03    |\n",
      "|    velocity_penalty     | -90.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 591         |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1791        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1962        |\n",
      "|    total_timesteps      | 3514368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016486008 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.00132     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    std                  | 0.709       |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -1.01e+03   |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.6e+03     |\n",
      "|    velocity_penalty     | -108        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 702         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1791        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 1975        |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024096927 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.00131     |\n",
      "|    loss                 | 6.98        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 0.708       |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 534         |\n",
      "|    position_penalty     | -252        |\n",
      "|    time                 | 695         |\n",
      "|    torque_penalty       | -208        |\n",
      "|    upright              | 349         |\n",
      "|    velocity_penalty     | -25.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 641         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1791        |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 1988        |\n",
      "|    total_timesteps      | 3563520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017272092 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.00131     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    std                  | 0.707       |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 92.9        |\n",
      "|    position_penalty     | -54.3       |\n",
      "|    time                 | 149         |\n",
      "|    torque_penalty       | -44.6       |\n",
      "|    upright              | 80.8        |\n",
      "|    velocity_penalty     | -11.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 730         |\n",
      "|    ep_rew_mean          | 1.56e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1791        |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 2002        |\n",
      "|    total_timesteps      | 3588096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015446636 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00131     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 58.3        |\n",
      "|    position_penalty     | -39.4       |\n",
      "|    time                 | 115         |\n",
      "|    torque_penalty       | -34.4       |\n",
      "|    upright              | 71.5        |\n",
      "|    velocity_penalty     | -8.45       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 764         |\n",
      "|    ep_rew_mean          | 1.65e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1792        |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2015        |\n",
      "|    total_timesteps      | 3612672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016365735 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0013      |\n",
      "|    loss                 | 86.3        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 61.9        |\n",
      "|    position_penalty     | -39.9       |\n",
      "|    time                 | 121         |\n",
      "|    torque_penalty       | -36.1       |\n",
      "|    upright              | 71.4        |\n",
      "|    velocity_penalty     | -8.44       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 701         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1792        |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020728825 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0013      |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 160         |\n",
      "|    position_penalty     | -55.6       |\n",
      "|    time                 | 212         |\n",
      "|    torque_penalty       | -63.6       |\n",
      "|    upright              | 136         |\n",
      "|    velocity_penalty     | -8.48       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 700         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1792        |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 2042        |\n",
      "|    total_timesteps      | 3661824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015457644 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00129     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -941        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.69e+03    |\n",
      "|    velocity_penalty     | -95.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 626         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1793        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2055        |\n",
      "|    total_timesteps      | 3686400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016231278 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.00129     |\n",
      "|    loss                 | 75          |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 69.9       |\n",
      "|    position_penalty     | -43.9      |\n",
      "|    time                 | 131        |\n",
      "|    torque_penalty       | -39.2      |\n",
      "|    upright              | 81.6       |\n",
      "|    velocity_penalty     | -9.92      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 710        |\n",
      "|    ep_rew_mean          | 1.54e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1793       |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 2069       |\n",
      "|    total_timesteps      | 3710976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02521128 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.00128    |\n",
      "|    loss                 | 136        |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | -0.00797   |\n",
      "|    std                  | 0.696      |\n",
      "|    value_loss           | 259        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 192         |\n",
      "|    position_penalty     | -61.1       |\n",
      "|    time                 | 262         |\n",
      "|    torque_penalty       | -78.4       |\n",
      "|    upright              | 104         |\n",
      "|    velocity_penalty     | -9.39       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 717         |\n",
      "|    ep_rew_mean          | 1.56e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1793        |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 2082        |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017236432 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.00128     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 107         |\n",
      "|    position_penalty     | -39.2       |\n",
      "|    time                 | 158         |\n",
      "|    torque_penalty       | -47.4       |\n",
      "|    upright              | 72.8        |\n",
      "|    velocity_penalty     | -9.53       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 814         |\n",
      "|    ep_rew_mean          | 1.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1793        |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2096        |\n",
      "|    total_timesteps      | 3760128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022047607 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00127     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 120        |\n",
      "|    position_penalty     | -44.2      |\n",
      "|    time                 | 192        |\n",
      "|    torque_penalty       | -57.5      |\n",
      "|    upright              | 128        |\n",
      "|    velocity_penalty     | -9.48      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 771        |\n",
      "|    ep_rew_mean          | 1.7e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1793       |\n",
      "|    iterations           | 154        |\n",
      "|    time_elapsed         | 2110       |\n",
      "|    total_timesteps      | 3784704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02616302 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.00127    |\n",
      "|    loss                 | 134        |\n",
      "|    n_updates            | 1530       |\n",
      "|    policy_gradient_loss | -0.00786   |\n",
      "|    std                  | 0.697      |\n",
      "|    value_loss           | 290        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -972        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.69e+03    |\n",
      "|    velocity_penalty     | -95.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 975         |\n",
      "|    ep_rew_mean          | 2.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1793        |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 2123        |\n",
      "|    total_timesteps      | 3809280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015966734 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.00126     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 109         |\n",
      "|    position_penalty     | -46.8       |\n",
      "|    time                 | 198         |\n",
      "|    torque_penalty       | -59.3       |\n",
      "|    upright              | 70.6        |\n",
      "|    velocity_penalty     | -11.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 870         |\n",
      "|    ep_rew_mean          | 1.94e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1794        |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2136        |\n",
      "|    total_timesteps      | 3833856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017495735 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.00126     |\n",
      "|    loss                 | 222         |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 449         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 90.6        |\n",
      "|    position_penalty     | -42.6       |\n",
      "|    time                 | 158         |\n",
      "|    torque_penalty       | -47.3       |\n",
      "|    upright              | 108         |\n",
      "|    velocity_penalty     | -8.89       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 728         |\n",
      "|    ep_rew_mean          | 1.59e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1794        |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 2150        |\n",
      "|    total_timesteps      | 3858432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013650764 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00125     |\n",
      "|    loss                 | 96.2        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -1.19e+03   |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.7e+03     |\n",
      "|    velocity_penalty     | -92.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 643         |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1794        |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 2163        |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019991457 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00125     |\n",
      "|    loss                 | 61.4        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 64.6        |\n",
      "|    position_penalty     | -34.7       |\n",
      "|    time                 | 120         |\n",
      "|    torque_penalty       | -36         |\n",
      "|    upright              | 62.1        |\n",
      "|    velocity_penalty     | -7.82       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 827         |\n",
      "|    ep_rew_mean          | 1.82e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1794        |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 2177        |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024740068 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.00124     |\n",
      "|    loss                 | 86.2        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 69.6       |\n",
      "|    position_penalty     | -39.5      |\n",
      "|    time                 | 128        |\n",
      "|    torque_penalty       | -38.1      |\n",
      "|    upright              | 80.7       |\n",
      "|    velocity_penalty     | -7.9       |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 911        |\n",
      "|    ep_rew_mean          | 2.03e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1794       |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 2191       |\n",
      "|    total_timesteps      | 3932160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02255626 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.00124    |\n",
      "|    loss                 | 100        |\n",
      "|    n_updates            | 1590       |\n",
      "|    policy_gradient_loss | -0.00881   |\n",
      "|    std                  | 0.695      |\n",
      "|    value_loss           | 269        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 163         |\n",
      "|    position_penalty     | -53.5       |\n",
      "|    time                 | 239         |\n",
      "|    torque_penalty       | -71.5       |\n",
      "|    upright              | 168         |\n",
      "|    velocity_penalty     | -10.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 994         |\n",
      "|    ep_rew_mean          | 2.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1794        |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 2204        |\n",
      "|    total_timesteps      | 3956736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019875757 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.00123     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 177         |\n",
      "|    position_penalty     | -53.3       |\n",
      "|    time                 | 252         |\n",
      "|    torque_penalty       | -75.5       |\n",
      "|    upright              | 179         |\n",
      "|    velocity_penalty     | -10.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 592         |\n",
      "|    ep_rew_mean          | 1.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1794        |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 2218        |\n",
      "|    total_timesteps      | 3981312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015142915 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.00123     |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 63          |\n",
      "|    position_penalty     | -40.3       |\n",
      "|    time                 | 120         |\n",
      "|    torque_penalty       | -36         |\n",
      "|    upright              | 71.4        |\n",
      "|    velocity_penalty     | -8.48       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 592         |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 2231        |\n",
      "|    total_timesteps      | 4005888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013062999 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.00122     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 446         |\n",
      "|    position_penalty     | -166        |\n",
      "|    time                 | 531         |\n",
      "|    torque_penalty       | -159        |\n",
      "|    upright              | 423         |\n",
      "|    velocity_penalty     | -26         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 611         |\n",
      "|    ep_rew_mean          | 1.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 2245        |\n",
      "|    total_timesteps      | 4030464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021429488 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00122     |\n",
      "|    loss                 | 91.8        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 84.8        |\n",
      "|    position_penalty     | -55.7       |\n",
      "|    time                 | 133         |\n",
      "|    torque_penalty       | -39.7       |\n",
      "|    upright              | 59.3        |\n",
      "|    velocity_penalty     | -12         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 729         |\n",
      "|    ep_rew_mean          | 1.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 2258        |\n",
      "|    total_timesteps      | 4055040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037783436 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.00121     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 92          |\n",
      "|    position_penalty     | -33         |\n",
      "|    time                 | 149         |\n",
      "|    torque_penalty       | -44.6       |\n",
      "|    upright              | 55.1        |\n",
      "|    velocity_penalty     | -8.37       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 706         |\n",
      "|    ep_rew_mean          | 1.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 2272        |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015963996 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.00121     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 89.6        |\n",
      "|    position_penalty     | -43.5       |\n",
      "|    time                 | 153         |\n",
      "|    torque_penalty       | -45.7       |\n",
      "|    upright              | 97.3        |\n",
      "|    velocity_penalty     | -9.32       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 636         |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 2285        |\n",
      "|    total_timesteps      | 4104192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019901065 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0012      |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 4.78e+03   |\n",
      "|    position_penalty     | -832       |\n",
      "|    time                 | 4.8e+03    |\n",
      "|    torque_penalty       | -1.44e+03  |\n",
      "|    upright              | 4.64e+03   |\n",
      "|    velocity_penalty     | -103       |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 568        |\n",
      "|    ep_rew_mean          | 1.19e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1795       |\n",
      "|    iterations           | 168        |\n",
      "|    time_elapsed         | 2299       |\n",
      "|    total_timesteps      | 4128768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02032197 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0012     |\n",
      "|    loss                 | 78.5       |\n",
      "|    n_updates            | 1670       |\n",
      "|    policy_gradient_loss | -0.0085    |\n",
      "|    std                  | 0.697      |\n",
      "|    value_loss           | 213        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 101         |\n",
      "|    position_penalty     | -52.1       |\n",
      "|    time                 | 140         |\n",
      "|    torque_penalty       | -42         |\n",
      "|    upright              | 68.8        |\n",
      "|    velocity_penalty     | -10.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 738         |\n",
      "|    ep_rew_mean          | 1.61e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 2312        |\n",
      "|    total_timesteps      | 4153344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019774387 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.00119     |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 53.9       |\n",
      "|    position_penalty     | -41        |\n",
      "|    time                 | 112        |\n",
      "|    torque_penalty       | -33.4      |\n",
      "|    upright              | 65.7       |\n",
      "|    velocity_penalty     | -9.13      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 640        |\n",
      "|    ep_rew_mean          | 1.36e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1795       |\n",
      "|    iterations           | 170        |\n",
      "|    time_elapsed         | 2326       |\n",
      "|    total_timesteps      | 4177920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01390059 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.00119    |\n",
      "|    loss                 | 118        |\n",
      "|    n_updates            | 1690       |\n",
      "|    policy_gradient_loss | -0.00677   |\n",
      "|    std                  | 0.701      |\n",
      "|    value_loss           | 307        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 168         |\n",
      "|    position_penalty     | -170        |\n",
      "|    time                 | 264         |\n",
      "|    torque_penalty       | -78.6       |\n",
      "|    upright              | 152         |\n",
      "|    velocity_penalty     | -32.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 554         |\n",
      "|    ep_rew_mean          | 1.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1796        |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 2339        |\n",
      "|    total_timesteps      | 4202496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016763907 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00119     |\n",
      "|    loss                 | 84.7        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 113         |\n",
      "|    position_penalty     | -38.8       |\n",
      "|    time                 | 181         |\n",
      "|    torque_penalty       | -54.1       |\n",
      "|    upright              | 98.5        |\n",
      "|    velocity_penalty     | -9.05       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 617         |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1796        |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 2353        |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019292578 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.00118     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 183          |\n",
      "|    position_penalty     | -163         |\n",
      "|    time                 | 261          |\n",
      "|    torque_penalty       | -77.8        |\n",
      "|    upright              | 163          |\n",
      "|    velocity_penalty     | -26.7        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 681          |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1796         |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 2366         |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127692735 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.6        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.00118      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.00996     |\n",
      "|    std                  | 0.703        |\n",
      "|    value_loss           | 233          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| reward_components/      |           |\n",
      "|    height               | 112       |\n",
      "|    position_penalty     | -39.2     |\n",
      "|    time                 | 150       |\n",
      "|    torque_penalty       | -45       |\n",
      "|    upright              | 59.9      |\n",
      "|    velocity_penalty     | -10.2     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 835       |\n",
      "|    ep_rew_mean          | 1.83e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1796      |\n",
      "|    iterations           | 174       |\n",
      "|    time_elapsed         | 2380      |\n",
      "|    total_timesteps      | 4276224   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0240648 |\n",
      "|    clip_fraction        | 0.251     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -12.6     |\n",
      "|    explained_variance   | 0.993     |\n",
      "|    learning_rate        | 0.00117   |\n",
      "|    loss                 | 29.9      |\n",
      "|    n_updates            | 1730      |\n",
      "|    policy_gradient_loss | -0.0113   |\n",
      "|    std                  | 0.702     |\n",
      "|    value_loss           | 95.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 497         |\n",
      "|    position_penalty     | -219        |\n",
      "|    time                 | 604         |\n",
      "|    torque_penalty       | -181        |\n",
      "|    upright              | 472         |\n",
      "|    velocity_penalty     | -35         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 888         |\n",
      "|    ep_rew_mean          | 1.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1796        |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 2393        |\n",
      "|    total_timesteps      | 4300800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016166061 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.00117     |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 368         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 136         |\n",
      "|    position_penalty     | -67         |\n",
      "|    time                 | 215         |\n",
      "|    torque_penalty       | -64.3       |\n",
      "|    upright              | 139         |\n",
      "|    velocity_penalty     | -12.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 903         |\n",
      "|    ep_rew_mean          | 1.99e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1796        |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 2407        |\n",
      "|    total_timesteps      | 4325376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017786134 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.00116     |\n",
      "|    loss                 | 94.7        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -1.06e+03   |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.53e+03    |\n",
      "|    velocity_penalty     | -102        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 958         |\n",
      "|    ep_rew_mean          | 2.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1797        |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 2420        |\n",
      "|    total_timesteps      | 4349952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016449526 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.00116     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 160         |\n",
      "|    position_penalty     | -46.1       |\n",
      "|    time                 | 186         |\n",
      "|    torque_penalty       | -55.8       |\n",
      "|    upright              | 83.4        |\n",
      "|    velocity_penalty     | -8.89       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 832         |\n",
      "|    ep_rew_mean          | 1.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1797        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 2433        |\n",
      "|    total_timesteps      | 4374528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014817298 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.00115     |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 436         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 483         |\n",
      "|    position_penalty     | -155        |\n",
      "|    time                 | 602         |\n",
      "|    torque_penalty       | -180        |\n",
      "|    upright              | 367         |\n",
      "|    velocity_penalty     | -18.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 871         |\n",
      "|    ep_rew_mean          | 1.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1797        |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 2447        |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017699122 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00115     |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -1.25e+03   |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.44e+03    |\n",
      "|    velocity_penalty     | -103        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 2.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1797        |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 2460        |\n",
      "|    total_timesteps      | 4423680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016437618 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.00114     |\n",
      "|    loss                 | 81.3        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 92.9        |\n",
      "|    position_penalty     | -52.2       |\n",
      "|    time                 | 155         |\n",
      "|    torque_penalty       | -46.3       |\n",
      "|    upright              | 91.4        |\n",
      "|    velocity_penalty     | -11.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 933         |\n",
      "|    ep_rew_mean          | 2.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1798        |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 2473        |\n",
      "|    total_timesteps      | 4448256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019003293 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00114     |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 156         |\n",
      "|    position_penalty     | -109        |\n",
      "|    time                 | 199         |\n",
      "|    torque_penalty       | -59.6       |\n",
      "|    upright              | 95.7        |\n",
      "|    velocity_penalty     | -16.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 977         |\n",
      "|    ep_rew_mean          | 2.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1798        |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 2487        |\n",
      "|    total_timesteps      | 4472832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023773031 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.00113     |\n",
      "|    loss                 | 56.1        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 80.1        |\n",
      "|    position_penalty     | -37.1       |\n",
      "|    time                 | 133         |\n",
      "|    torque_penalty       | -39.5       |\n",
      "|    upright              | 55.5        |\n",
      "|    velocity_penalty     | -8.55       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 982         |\n",
      "|    ep_rew_mean          | 2.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1798        |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 2500        |\n",
      "|    total_timesteps      | 4497408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019886045 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.00113     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 122         |\n",
      "|    position_penalty     | -50.7       |\n",
      "|    time                 | 196         |\n",
      "|    torque_penalty       | -58.8       |\n",
      "|    upright              | 136         |\n",
      "|    velocity_penalty     | -9.41       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | 1.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1798        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 2513        |\n",
      "|    total_timesteps      | 4521984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014793378 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.00112     |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 440         |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| reward_components/      |          |\n",
      "|    height               | 68.9     |\n",
      "|    position_penalty     | -36.6    |\n",
      "|    time                 | 128      |\n",
      "|    torque_penalty       | -38.3    |\n",
      "|    upright              | 67.8     |\n",
      "|    velocity_penalty     | -8.06    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 485      |\n",
      "|    ep_rew_mean          | 984      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1798     |\n",
      "|    iterations           | 185      |\n",
      "|    time_elapsed         | 2527     |\n",
      "|    total_timesteps      | 4546560  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.014909 |\n",
      "|    clip_fraction        | 0.18     |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -12.5    |\n",
      "|    explained_variance   | 0.994    |\n",
      "|    learning_rate        | 0.00112  |\n",
      "|    loss                 | 86       |\n",
      "|    n_updates            | 1840     |\n",
      "|    policy_gradient_loss | -0.0115  |\n",
      "|    std                  | 0.697    |\n",
      "|    value_loss           | 160      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 137        |\n",
      "|    position_penalty     | -70        |\n",
      "|    time                 | 197        |\n",
      "|    torque_penalty       | -58.8      |\n",
      "|    upright              | 105        |\n",
      "|    velocity_penalty     | -11.9      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 636        |\n",
      "|    ep_rew_mean          | 1.33e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1799       |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 2540       |\n",
      "|    total_timesteps      | 4571136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01372088 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.00111    |\n",
      "|    loss                 | 114        |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | -0.00918   |\n",
      "|    std                  | 0.696      |\n",
      "|    value_loss           | 166        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 157         |\n",
      "|    position_penalty     | -48.8       |\n",
      "|    time                 | 233         |\n",
      "|    torque_penalty       | -69.7       |\n",
      "|    upright              | 138         |\n",
      "|    velocity_penalty     | -10         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 703         |\n",
      "|    ep_rew_mean          | 1.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1799        |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 2554        |\n",
      "|    total_timesteps      | 4595712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016657667 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00111     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -1.1e+03    |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.52e+03    |\n",
      "|    velocity_penalty     | -95.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 798         |\n",
      "|    ep_rew_mean          | 1.74e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1799        |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 2567        |\n",
      "|    total_timesteps      | 4620288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016399028 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0011      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 221         |\n",
      "|    position_penalty     | -167        |\n",
      "|    time                 | 305         |\n",
      "|    torque_penalty       | -91.4       |\n",
      "|    upright              | 210         |\n",
      "|    velocity_penalty     | -24.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 929         |\n",
      "|    ep_rew_mean          | 2.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1799        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 2580        |\n",
      "|    total_timesteps      | 4644864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021809824 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0011      |\n",
      "|    loss                 | 61.1        |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -955        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.62e+03    |\n",
      "|    velocity_penalty     | -90.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | 2.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1800        |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 2594        |\n",
      "|    total_timesteps      | 4669440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027580613 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.00109     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 369         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 108        |\n",
      "|    position_penalty     | -62.7      |\n",
      "|    time                 | 166        |\n",
      "|    torque_penalty       | -49.7      |\n",
      "|    upright              | 85.1       |\n",
      "|    velocity_penalty     | -10.8      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.24e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1800       |\n",
      "|    iterations           | 191        |\n",
      "|    time_elapsed         | 2607       |\n",
      "|    total_timesteps      | 4694016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01306091 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.00109    |\n",
      "|    loss                 | 143        |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | -0.00877   |\n",
      "|    std                  | 0.698      |\n",
      "|    value_loss           | 355        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| reward_components/      |           |\n",
      "|    height               | 4.79e+03  |\n",
      "|    position_penalty     | -764      |\n",
      "|    time                 | 4.8e+03   |\n",
      "|    torque_penalty       | -1.44e+03 |\n",
      "|    upright              | 4.42e+03  |\n",
      "|    velocity_penalty     | -118      |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 899       |\n",
      "|    ep_rew_mean          | 1.99e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1800      |\n",
      "|    iterations           | 192       |\n",
      "|    time_elapsed         | 2620      |\n",
      "|    total_timesteps      | 4718592   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0139964 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -12.5     |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.00108   |\n",
      "|    loss                 | 163       |\n",
      "|    n_updates            | 1910      |\n",
      "|    policy_gradient_loss | -0.0108   |\n",
      "|    std                  | 0.699     |\n",
      "|    value_loss           | 287       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 236         |\n",
      "|    position_penalty     | -165        |\n",
      "|    time                 | 307         |\n",
      "|    torque_penalty       | -91.7       |\n",
      "|    upright              | 227         |\n",
      "|    velocity_penalty     | -25.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 777         |\n",
      "|    ep_rew_mean          | 1.69e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1800        |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 2634        |\n",
      "|    total_timesteps      | 4743168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012971219 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00108     |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 4.79e+03   |\n",
      "|    position_penalty     | -967       |\n",
      "|    time                 | 4.8e+03    |\n",
      "|    torque_penalty       | -1.44e+03  |\n",
      "|    upright              | 4.64e+03   |\n",
      "|    velocity_penalty     | -96.7      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 692        |\n",
      "|    ep_rew_mean          | 1.48e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1800       |\n",
      "|    iterations           | 194        |\n",
      "|    time_elapsed         | 2647       |\n",
      "|    total_timesteps      | 4767744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01535553 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.00108    |\n",
      "|    loss                 | 136        |\n",
      "|    n_updates            | 1930       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    std                  | 0.698      |\n",
      "|    value_loss           | 264        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 116         |\n",
      "|    position_penalty     | -41.3       |\n",
      "|    time                 | 149         |\n",
      "|    torque_penalty       | -44.7       |\n",
      "|    upright              | 68.1        |\n",
      "|    velocity_penalty     | -9.84       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 719         |\n",
      "|    ep_rew_mean          | 1.56e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1801        |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 2660        |\n",
      "|    total_timesteps      | 4792320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017400831 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00107     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 351        |\n",
      "|    position_penalty     | -117       |\n",
      "|    time                 | 441        |\n",
      "|    torque_penalty       | -132       |\n",
      "|    upright              | 298        |\n",
      "|    velocity_penalty     | -17.1      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 796        |\n",
      "|    ep_rew_mean          | 1.76e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1801       |\n",
      "|    iterations           | 196        |\n",
      "|    time_elapsed         | 2674       |\n",
      "|    total_timesteps      | 4816896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01687528 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.00107    |\n",
      "|    loss                 | 99.6       |\n",
      "|    n_updates            | 1950       |\n",
      "|    policy_gradient_loss | -0.00861   |\n",
      "|    std                  | 0.699      |\n",
      "|    value_loss           | 170        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 155         |\n",
      "|    position_penalty     | -95.7       |\n",
      "|    time                 | 220         |\n",
      "|    torque_penalty       | -65.9       |\n",
      "|    upright              | 136         |\n",
      "|    velocity_penalty     | -16.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 866         |\n",
      "|    ep_rew_mean          | 1.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1801        |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 2687        |\n",
      "|    total_timesteps      | 4841472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017775178 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.00106     |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 439         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 86.6        |\n",
      "|    position_penalty     | -36.6       |\n",
      "|    time                 | 146         |\n",
      "|    torque_penalty       | -43.7       |\n",
      "|    upright              | 59.7        |\n",
      "|    velocity_penalty     | -11.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 863         |\n",
      "|    ep_rew_mean          | 1.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1801        |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 2700        |\n",
      "|    total_timesteps      | 4866048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018131496 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.00106     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 1.66e+03   |\n",
      "|    position_penalty     | -304       |\n",
      "|    time                 | 1.75e+03   |\n",
      "|    torque_penalty       | -525       |\n",
      "|    upright              | 1.57e+03   |\n",
      "|    velocity_penalty     | -39.6      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 918        |\n",
      "|    ep_rew_mean          | 2.07e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1801       |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 2714       |\n",
      "|    total_timesteps      | 4890624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04023443 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.00105    |\n",
      "|    loss                 | 57.8       |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | -0.00554   |\n",
      "|    std                  | 0.699      |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 98.4        |\n",
      "|    position_penalty     | -51.7       |\n",
      "|    time                 | 165         |\n",
      "|    torque_penalty       | -49.3       |\n",
      "|    upright              | 99.8        |\n",
      "|    velocity_penalty     | -10.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 819         |\n",
      "|    ep_rew_mean          | 1.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1801        |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 2727        |\n",
      "|    total_timesteps      | 4915200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017298259 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.00105     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 518         |\n",
      "|    position_penalty     | -160        |\n",
      "|    time                 | 600         |\n",
      "|    torque_penalty       | -180        |\n",
      "|    upright              | 485         |\n",
      "|    velocity_penalty     | -26.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 896         |\n",
      "|    ep_rew_mean          | 2.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1802        |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 2740        |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017937528 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.00104     |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 386         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 128         |\n",
      "|    position_penalty     | -46.5       |\n",
      "|    time                 | 199         |\n",
      "|    torque_penalty       | -59.6       |\n",
      "|    upright              | 131         |\n",
      "|    velocity_penalty     | -9.52       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 851         |\n",
      "|    ep_rew_mean          | 1.91e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1802        |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 2754        |\n",
      "|    total_timesteps      | 4964352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014960521 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00104     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 88.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 115         |\n",
      "|    position_penalty     | -40.9       |\n",
      "|    time                 | 182         |\n",
      "|    torque_penalty       | -54.5       |\n",
      "|    upright              | 74.1        |\n",
      "|    velocity_penalty     | -11.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 794         |\n",
      "|    ep_rew_mean          | 1.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1802        |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 2767        |\n",
      "|    total_timesteps      | 4988928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018438524 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.00103     |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 473         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 233         |\n",
      "|    position_penalty     | -124        |\n",
      "|    time                 | 338         |\n",
      "|    torque_penalty       | -101        |\n",
      "|    upright              | 189         |\n",
      "|    velocity_penalty     | -26.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 887         |\n",
      "|    ep_rew_mean          | 2.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1802        |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 2781        |\n",
      "|    total_timesteps      | 5013504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020230167 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.00103     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.53e+03    |\n",
      "|    position_penalty     | -664        |\n",
      "|    time                 | 4.65e+03    |\n",
      "|    torque_penalty       | -1.39e+03   |\n",
      "|    upright              | 4.17e+03    |\n",
      "|    velocity_penalty     | -95.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 2.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1802        |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 2794        |\n",
      "|    total_timesteps      | 5038080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019951925 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.00102     |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 142         |\n",
      "|    position_penalty     | -105        |\n",
      "|    time                 | 206         |\n",
      "|    torque_penalty       | -61.4       |\n",
      "|    upright              | 125         |\n",
      "|    velocity_penalty     | -18.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 2.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1803        |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 2807        |\n",
      "|    total_timesteps      | 5062656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014942449 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.00102     |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 366         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 293        |\n",
      "|    position_penalty     | -135       |\n",
      "|    time                 | 404        |\n",
      "|    torque_penalty       | -121       |\n",
      "|    upright              | 207        |\n",
      "|    velocity_penalty     | -19.9      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 2.54e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1803       |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 2821       |\n",
      "|    total_timesteps      | 5087232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02836544 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.00101    |\n",
      "|    loss                 | 88.5       |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | -0.00842   |\n",
      "|    std                  | 0.704      |\n",
      "|    value_loss           | 177        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 72.5        |\n",
      "|    position_penalty     | -37.6       |\n",
      "|    time                 | 135         |\n",
      "|    torque_penalty       | -40.5       |\n",
      "|    upright              | 72.1        |\n",
      "|    velocity_penalty     | -8.23       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 786         |\n",
      "|    ep_rew_mean          | 1.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1803        |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 2834        |\n",
      "|    total_timesteps      | 5111808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016006134 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.00101     |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 437         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 123         |\n",
      "|    position_penalty     | -42.4       |\n",
      "|    time                 | 198         |\n",
      "|    torque_penalty       | -59.4       |\n",
      "|    upright              | 117         |\n",
      "|    velocity_penalty     | -8.7        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 717         |\n",
      "|    ep_rew_mean          | 1.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1803        |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 2847        |\n",
      "|    total_timesteps      | 5136384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013278745 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 83.8        |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 236         |\n",
      "|    position_penalty     | -104        |\n",
      "|    time                 | 310         |\n",
      "|    torque_penalty       | -92.6       |\n",
      "|    upright              | 166         |\n",
      "|    velocity_penalty     | -15         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | 1.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1803        |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 2861        |\n",
      "|    total_timesteps      | 5160960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020559618 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.000998    |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    std                  | 0.701       |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 109         |\n",
      "|    position_penalty     | -43.9       |\n",
      "|    time                 | 177         |\n",
      "|    torque_penalty       | -52.9       |\n",
      "|    upright              | 116         |\n",
      "|    velocity_penalty     | -9.43       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 703         |\n",
      "|    ep_rew_mean          | 1.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1803        |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 2874        |\n",
      "|    total_timesteps      | 5185536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015268863 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.000994    |\n",
      "|    loss                 | 306         |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 641         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -693        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.69e+03    |\n",
      "|    velocity_penalty     | -87.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 754         |\n",
      "|    ep_rew_mean          | 1.68e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1804        |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 2887        |\n",
      "|    total_timesteps      | 5210112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014124676 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.000989    |\n",
      "|    loss                 | 89          |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 72          |\n",
      "|    position_penalty     | -42.3       |\n",
      "|    time                 | 140         |\n",
      "|    torque_penalty       | -41.9       |\n",
      "|    upright              | 79.1        |\n",
      "|    velocity_penalty     | -8.65       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 817         |\n",
      "|    ep_rew_mean          | 1.84e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1804        |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 2901        |\n",
      "|    total_timesteps      | 5234688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019668503 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.000984    |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.8e+03     |\n",
      "|    position_penalty     | -564        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.65e+03    |\n",
      "|    velocity_penalty     | -86.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 808         |\n",
      "|    ep_rew_mean          | 1.82e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1804        |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 2914        |\n",
      "|    total_timesteps      | 5259264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016381498 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000979    |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 110         |\n",
      "|    position_penalty     | -65.4       |\n",
      "|    time                 | 163         |\n",
      "|    torque_penalty       | -48.4       |\n",
      "|    upright              | 83.4        |\n",
      "|    velocity_penalty     | -12.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 798         |\n",
      "|    ep_rew_mean          | 1.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1804        |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 2927        |\n",
      "|    total_timesteps      | 5283840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015587394 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.000974    |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 93.7        |\n",
      "|    position_penalty     | -85.5       |\n",
      "|    time                 | 169         |\n",
      "|    torque_penalty       | -50.6       |\n",
      "|    upright              | 100         |\n",
      "|    velocity_penalty     | -15.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 820         |\n",
      "|    ep_rew_mean          | 1.84e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1804        |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 2941        |\n",
      "|    total_timesteps      | 5308416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014505514 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.00097     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 243         |\n",
      "|    position_penalty     | -160        |\n",
      "|    time                 | 371         |\n",
      "|    torque_penalty       | -111        |\n",
      "|    upright              | 167         |\n",
      "|    velocity_penalty     | -33.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 756         |\n",
      "|    ep_rew_mean          | 1.67e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1804        |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 2954        |\n",
      "|    total_timesteps      | 5332992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012696274 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.000965    |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 373         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 3.45e+03    |\n",
      "|    position_penalty     | -547        |\n",
      "|    time                 | 3.56e+03    |\n",
      "|    torque_penalty       | -1.07e+03   |\n",
      "|    upright              | 3.25e+03    |\n",
      "|    velocity_penalty     | -82.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 893         |\n",
      "|    ep_rew_mean          | 2.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1805        |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 2968        |\n",
      "|    total_timesteps      | 5357568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014711815 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.00096     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 85          |\n",
      "|    position_penalty     | -39.6       |\n",
      "|    time                 | 149         |\n",
      "|    torque_penalty       | -44.7       |\n",
      "|    upright              | 69          |\n",
      "|    velocity_penalty     | -8.24       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 780         |\n",
      "|    ep_rew_mean          | 1.73e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1805        |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 2981        |\n",
      "|    total_timesteps      | 5382144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014793381 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.000955    |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -613        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.58e+03    |\n",
      "|    velocity_penalty     | -87.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 842         |\n",
      "|    ep_rew_mean          | 1.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1805        |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 2994        |\n",
      "|    total_timesteps      | 5406720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015864624 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00095     |\n",
      "|    loss                 | 85.8        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 63.4        |\n",
      "|    position_penalty     | -39.2       |\n",
      "|    time                 | 121         |\n",
      "|    torque_penalty       | -36.2       |\n",
      "|    upright              | 67.3        |\n",
      "|    velocity_penalty     | -8.49       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 962         |\n",
      "|    ep_rew_mean          | 2.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1805        |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 3008        |\n",
      "|    total_timesteps      | 5431296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012782946 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000946    |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 134         |\n",
      "|    position_penalty     | -58.1       |\n",
      "|    time                 | 217         |\n",
      "|    torque_penalty       | -65         |\n",
      "|    upright              | 129         |\n",
      "|    velocity_penalty     | -11.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 936         |\n",
      "|    ep_rew_mean          | 2.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1805        |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 3021        |\n",
      "|    total_timesteps      | 5455872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012245563 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.000941    |\n",
      "|    loss                 | 76.5        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 484         |\n",
      "|    position_penalty     | -200        |\n",
      "|    time                 | 565         |\n",
      "|    torque_penalty       | -169        |\n",
      "|    upright              | 364         |\n",
      "|    velocity_penalty     | -32         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 2.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1805        |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 3034        |\n",
      "|    total_timesteps      | 5480448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018044112 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000936    |\n",
      "|    loss                 | 76.5        |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 114         |\n",
      "|    position_penalty     | -79.2       |\n",
      "|    time                 | 171         |\n",
      "|    torque_penalty       | -50.7       |\n",
      "|    upright              | 93.9        |\n",
      "|    velocity_penalty     | -14.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 2.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1805        |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 3048        |\n",
      "|    total_timesteps      | 5505024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015356702 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.000931    |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 409         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 143         |\n",
      "|    position_penalty     | -49.4       |\n",
      "|    time                 | 178         |\n",
      "|    torque_penalty       | -53.3       |\n",
      "|    upright              | 93.3        |\n",
      "|    velocity_penalty     | -8.93       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 884         |\n",
      "|    ep_rew_mean          | 2.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1806        |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 3061        |\n",
      "|    total_timesteps      | 5529600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016382331 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.000927    |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 540         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 193         |\n",
      "|    position_penalty     | -166        |\n",
      "|    time                 | 337         |\n",
      "|    torque_penalty       | -101        |\n",
      "|    upright              | 177         |\n",
      "|    velocity_penalty     | -30.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 649         |\n",
      "|    ep_rew_mean          | 1.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1806        |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 3074        |\n",
      "|    total_timesteps      | 5554176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021462848 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.000922    |\n",
      "|    loss                 | 8.31        |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 325         |\n",
      "|    position_penalty     | -182        |\n",
      "|    time                 | 398         |\n",
      "|    torque_penalty       | -119        |\n",
      "|    upright              | 267         |\n",
      "|    velocity_penalty     | -28.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 652         |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1806        |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 3088        |\n",
      "|    total_timesteps      | 5578752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015751926 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.000917    |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 268         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 91.7        |\n",
      "|    position_penalty     | -51.1       |\n",
      "|    time                 | 152         |\n",
      "|    torque_penalty       | -45.4       |\n",
      "|    upright              | 86.7        |\n",
      "|    velocity_penalty     | -10.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 620         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1806        |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 3101        |\n",
      "|    total_timesteps      | 5603328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015607182 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000912    |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 165        |\n",
      "|    position_penalty     | -90        |\n",
      "|    time                 | 264        |\n",
      "|    torque_penalty       | -79        |\n",
      "|    upright              | 154        |\n",
      "|    velocity_penalty     | -15.5      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 797        |\n",
      "|    ep_rew_mean          | 1.79e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1806       |\n",
      "|    iterations           | 229        |\n",
      "|    time_elapsed         | 3115       |\n",
      "|    total_timesteps      | 5627904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02711007 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000907   |\n",
      "|    loss                 | 6.21       |\n",
      "|    n_updates            | 2280       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 0.691      |\n",
      "|    value_loss           | 22.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 100         |\n",
      "|    position_penalty     | -81.5       |\n",
      "|    time                 | 142         |\n",
      "|    torque_penalty       | -42.5       |\n",
      "|    upright              | 63.9        |\n",
      "|    velocity_penalty     | -11.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 721         |\n",
      "|    ep_rew_mean          | 1.59e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1806        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 3128        |\n",
      "|    total_timesteps      | 5652480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030962778 |\n",
      "|    clip_fraction        | 0.545       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000903    |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 76.8         |\n",
      "|    position_penalty     | -46.7        |\n",
      "|    time                 | 139          |\n",
      "|    torque_penalty       | -41.6        |\n",
      "|    upright              | 81.1         |\n",
      "|    velocity_penalty     | -10.2        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 786          |\n",
      "|    ep_rew_mean          | 1.75e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1806         |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 3141         |\n",
      "|    total_timesteps      | 5677056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112134395 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.4        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.000898     |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 2300         |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 0.69         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -624        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.35e+03    |\n",
      "|    velocity_penalty     | -89.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 787         |\n",
      "|    ep_rew_mean          | 1.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1807        |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 3155        |\n",
      "|    total_timesteps      | 5701632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012808907 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.000893    |\n",
      "|    loss                 | 80          |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 144         |\n",
      "|    position_penalty     | -95.3       |\n",
      "|    time                 | 202         |\n",
      "|    torque_penalty       | -60.4       |\n",
      "|    upright              | 87.5        |\n",
      "|    velocity_penalty     | -16         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 787         |\n",
      "|    ep_rew_mean          | 1.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1807        |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 3168        |\n",
      "|    total_timesteps      | 5726208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018174104 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000888    |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 170         |\n",
      "|    position_penalty     | -111        |\n",
      "|    time                 | 223         |\n",
      "|    torque_penalty       | -66.9       |\n",
      "|    upright              | 115         |\n",
      "|    velocity_penalty     | -18         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 873         |\n",
      "|    ep_rew_mean          | 1.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1807        |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 3181        |\n",
      "|    total_timesteps      | 5750784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013134197 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000883    |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 102         |\n",
      "|    position_penalty     | -48.3       |\n",
      "|    time                 | 176         |\n",
      "|    torque_penalty       | -52.4       |\n",
      "|    upright              | 105         |\n",
      "|    velocity_penalty     | -9.03       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 893         |\n",
      "|    ep_rew_mean          | 2.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1807        |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 3195        |\n",
      "|    total_timesteps      | 5775360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013479303 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.000879    |\n",
      "|    loss                 | 74          |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 484        |\n",
      "|    position_penalty     | -153       |\n",
      "|    time                 | 555        |\n",
      "|    torque_penalty       | -166       |\n",
      "|    upright              | 405        |\n",
      "|    velocity_penalty     | -23.1      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | 2.36e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1807       |\n",
      "|    iterations           | 236        |\n",
      "|    time_elapsed         | 3208       |\n",
      "|    total_timesteps      | 5799936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01660628 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.000874   |\n",
      "|    loss                 | 76.5       |\n",
      "|    n_updates            | 2350       |\n",
      "|    policy_gradient_loss | -0.00924   |\n",
      "|    std                  | 0.69       |\n",
      "|    value_loss           | 188        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 95.5        |\n",
      "|    position_penalty     | -44.7       |\n",
      "|    time                 | 152         |\n",
      "|    torque_penalty       | -45.2       |\n",
      "|    upright              | 67.2        |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 871         |\n",
      "|    ep_rew_mean          | 1.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1807        |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 3221        |\n",
      "|    total_timesteps      | 5824512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016907528 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000869    |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 375         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 318         |\n",
      "|    position_penalty     | -148        |\n",
      "|    time                 | 396         |\n",
      "|    torque_penalty       | -119        |\n",
      "|    upright              | 270         |\n",
      "|    velocity_penalty     | -19.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 531         |\n",
      "|    ep_rew_mean          | 1.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1807        |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 3235        |\n",
      "|    total_timesteps      | 5849088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014760929 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.000864    |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 91.2        |\n",
      "|    position_penalty     | -47.7       |\n",
      "|    time                 | 163         |\n",
      "|    torque_penalty       | -48.7       |\n",
      "|    upright              | 90          |\n",
      "|    velocity_penalty     | -9.61       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 555         |\n",
      "|    ep_rew_mean          | 1.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1808        |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 3248        |\n",
      "|    total_timesteps      | 5873664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013570056 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.000859    |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 4.78e+03   |\n",
      "|    position_penalty     | -561       |\n",
      "|    time                 | 4.8e+03    |\n",
      "|    torque_penalty       | -1.44e+03  |\n",
      "|    upright              | 4.54e+03   |\n",
      "|    velocity_penalty     | -95.7      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 828        |\n",
      "|    ep_rew_mean          | 1.87e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1808       |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 3262       |\n",
      "|    total_timesteps      | 5898240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02811566 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.000855   |\n",
      "|    loss                 | 118        |\n",
      "|    n_updates            | 2390       |\n",
      "|    policy_gradient_loss | -0.00582   |\n",
      "|    std                  | 0.689      |\n",
      "|    value_loss           | 187        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 94.4        |\n",
      "|    position_penalty     | -53.4       |\n",
      "|    time                 | 170         |\n",
      "|    torque_penalty       | -50.7       |\n",
      "|    upright              | 104         |\n",
      "|    velocity_penalty     | -9          |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 858         |\n",
      "|    ep_rew_mean          | 1.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1808        |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 3275        |\n",
      "|    total_timesteps      | 5922816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019917378 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.00085     |\n",
      "|    loss                 | 254         |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 546         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -546        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.54e+03    |\n",
      "|    velocity_penalty     | -85.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 901         |\n",
      "|    ep_rew_mean          | 2.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1808        |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 3288        |\n",
      "|    total_timesteps      | 5947392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018529972 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.000845    |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -482        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.58e+03    |\n",
      "|    velocity_penalty     | -84         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 878         |\n",
      "|    ep_rew_mean          | 2.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1808        |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 3302        |\n",
      "|    total_timesteps      | 5971968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029970238 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.00084     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    std                  | 0.687       |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 106        |\n",
      "|    position_penalty     | -73        |\n",
      "|    time                 | 167        |\n",
      "|    torque_penalty       | -49.6      |\n",
      "|    upright              | 97.7       |\n",
      "|    velocity_penalty     | -12.3      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 789        |\n",
      "|    ep_rew_mean          | 1.77e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1808       |\n",
      "|    iterations           | 244        |\n",
      "|    time_elapsed         | 3315       |\n",
      "|    total_timesteps      | 5996544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02156349 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.3      |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.000835   |\n",
      "|    loss                 | 196        |\n",
      "|    n_updates            | 2430       |\n",
      "|    policy_gradient_loss | -0.00561   |\n",
      "|    std                  | 0.686      |\n",
      "|    value_loss           | 441        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.77e+03    |\n",
      "|    position_penalty     | -637        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.62e+03    |\n",
      "|    velocity_penalty     | -98         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 884         |\n",
      "|    ep_rew_mean          | 2.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1808        |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 3328        |\n",
      "|    total_timesteps      | 6021120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016702823 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.000831    |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.686       |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 516         |\n",
      "|    position_penalty     | -179        |\n",
      "|    time                 | 625         |\n",
      "|    torque_penalty       | -187        |\n",
      "|    upright              | 425         |\n",
      "|    velocity_penalty     | -21.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1808        |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 3342        |\n",
      "|    total_timesteps      | 6045696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021233767 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.000826    |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    std                  | 0.686       |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 125         |\n",
      "|    position_penalty     | -67.3       |\n",
      "|    time                 | 197         |\n",
      "|    torque_penalty       | -58.9       |\n",
      "|    upright              | 123         |\n",
      "|    velocity_penalty     | -12.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 750         |\n",
      "|    ep_rew_mean          | 1.69e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 3355        |\n",
      "|    total_timesteps      | 6070272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016496623 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.000821    |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    std                  | 0.687       |\n",
      "|    value_loss           | 530         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 84.2        |\n",
      "|    position_penalty     | -43.4       |\n",
      "|    time                 | 119         |\n",
      "|    torque_penalty       | -35.7       |\n",
      "|    upright              | 67.1        |\n",
      "|    velocity_penalty     | -10.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 503         |\n",
      "|    ep_rew_mean          | 1.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 3368        |\n",
      "|    total_timesteps      | 6094848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013158617 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.000816    |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    std                  | 0.688       |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.77e+03    |\n",
      "|    position_penalty     | -598        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.66e+03    |\n",
      "|    velocity_penalty     | -101        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | 1.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 3382        |\n",
      "|    total_timesteps      | 6119424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017946145 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.000812    |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    std                  | 0.688       |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 92.2        |\n",
      "|    position_penalty     | -30.6       |\n",
      "|    time                 | 121         |\n",
      "|    torque_penalty       | -36.3       |\n",
      "|    upright              | 53.7        |\n",
      "|    velocity_penalty     | -8.9        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 793         |\n",
      "|    ep_rew_mean          | 1.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 3395        |\n",
      "|    total_timesteps      | 6144000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036793843 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.000807    |\n",
      "|    loss                 | 94.1        |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 58.1        |\n",
      "|    position_penalty     | -38.7       |\n",
      "|    time                 | 116         |\n",
      "|    torque_penalty       | -34.8       |\n",
      "|    upright              | 60.9        |\n",
      "|    velocity_penalty     | -8.68       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 831         |\n",
      "|    ep_rew_mean          | 1.91e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 3408        |\n",
      "|    total_timesteps      | 6168576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021801954 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.000802    |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 469         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 110        |\n",
      "|    position_penalty     | -68.4      |\n",
      "|    time                 | 168        |\n",
      "|    torque_penalty       | -49.8      |\n",
      "|    upright              | 102        |\n",
      "|    velocity_penalty     | -13        |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 965        |\n",
      "|    ep_rew_mean          | 2.25e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1809       |\n",
      "|    iterations           | 252        |\n",
      "|    time_elapsed         | 3422       |\n",
      "|    total_timesteps      | 6193152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01569585 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.000797   |\n",
      "|    loss                 | 53.4       |\n",
      "|    n_updates            | 2510       |\n",
      "|    policy_gradient_loss | -0.0095    |\n",
      "|    std                  | 0.69       |\n",
      "|    value_loss           | 187        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 160         |\n",
      "|    position_penalty     | -62.7       |\n",
      "|    time                 | 240         |\n",
      "|    torque_penalty       | -71.8       |\n",
      "|    upright              | 160         |\n",
      "|    velocity_penalty     | -10.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 945         |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 3435        |\n",
      "|    total_timesteps      | 6217728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016272098 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.000792    |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 4.78e+03   |\n",
      "|    position_penalty     | -556       |\n",
      "|    time                 | 4.8e+03    |\n",
      "|    torque_penalty       | -1.44e+03  |\n",
      "|    upright              | 4.63e+03   |\n",
      "|    velocity_penalty     | -97.5      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 850        |\n",
      "|    ep_rew_mean          | 1.93e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1809       |\n",
      "|    iterations           | 254        |\n",
      "|    time_elapsed         | 3449       |\n",
      "|    total_timesteps      | 6242304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01208239 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.000788   |\n",
      "|    loss                 | 204        |\n",
      "|    n_updates            | 2530       |\n",
      "|    policy_gradient_loss | -0.00903   |\n",
      "|    std                  | 0.691      |\n",
      "|    value_loss           | 460        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -576        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.67e+03    |\n",
      "|    velocity_penalty     | -95.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 857         |\n",
      "|    ep_rew_mean          | 1.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 3462        |\n",
      "|    total_timesteps      | 6266880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014018808 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.000783    |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -507        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.67e+03    |\n",
      "|    velocity_penalty     | -100        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 787         |\n",
      "|    ep_rew_mean          | 1.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1809        |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 3476        |\n",
      "|    total_timesteps      | 6291456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013530937 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.000778    |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 62.9       |\n",
      "|    position_penalty     | -42.1      |\n",
      "|    time                 | 128        |\n",
      "|    torque_penalty       | -38.3      |\n",
      "|    upright              | 67.9       |\n",
      "|    velocity_penalty     | -9.5       |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 880        |\n",
      "|    ep_rew_mean          | 2e+03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1810       |\n",
      "|    iterations           | 257        |\n",
      "|    time_elapsed         | 3489       |\n",
      "|    total_timesteps      | 6316032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01494632 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.000773   |\n",
      "|    loss                 | 148        |\n",
      "|    n_updates            | 2560       |\n",
      "|    policy_gradient_loss | -0.00786   |\n",
      "|    std                  | 0.69       |\n",
      "|    value_loss           | 394        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 61.7        |\n",
      "|    position_penalty     | -47.2       |\n",
      "|    time                 | 130         |\n",
      "|    torque_penalty       | -38.9       |\n",
      "|    upright              | 72          |\n",
      "|    velocity_penalty     | -9.94       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 2.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1810        |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 3502        |\n",
      "|    total_timesteps      | 6340608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014265272 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.000768    |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 75.1        |\n",
      "|    position_penalty     | -52.2       |\n",
      "|    time                 | 138         |\n",
      "|    torque_penalty       | -41.2       |\n",
      "|    upright              | 78.9        |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 2.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1810        |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 3516        |\n",
      "|    total_timesteps      | 6365184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013968094 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.000764    |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 429         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -443        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.65e+03    |\n",
      "|    velocity_penalty     | -90.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 2.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1810        |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 3529        |\n",
      "|    total_timesteps      | 6389760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014270708 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.000759    |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 86.8        |\n",
      "|    position_penalty     | -47.6       |\n",
      "|    time                 | 157         |\n",
      "|    torque_penalty       | -46.5       |\n",
      "|    upright              | 94.1        |\n",
      "|    velocity_penalty     | -9.1        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 793         |\n",
      "|    ep_rew_mean          | 1.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1810        |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 3542        |\n",
      "|    total_timesteps      | 6414336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014274421 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000754    |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -508        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.62e+03    |\n",
      "|    velocity_penalty     | -100        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 759         |\n",
      "|    ep_rew_mean          | 1.71e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1810        |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 3556        |\n",
      "|    total_timesteps      | 6438912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014038566 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000749    |\n",
      "|    loss                 | 219         |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 434         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 4.78e+03     |\n",
      "|    position_penalty     | -538         |\n",
      "|    time                 | 4.8e+03      |\n",
      "|    torque_penalty       | -1.44e+03    |\n",
      "|    upright              | 4.54e+03     |\n",
      "|    velocity_penalty     | -103         |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 929          |\n",
      "|    ep_rew_mean          | 2.14e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1810         |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 3569         |\n",
      "|    total_timesteps      | 6463488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154425455 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.4        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.000744     |\n",
      "|    loss                 | 54.1         |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 0.693        |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 134        |\n",
      "|    position_penalty     | -60.1      |\n",
      "|    time                 | 204        |\n",
      "|    torque_penalty       | -61.1      |\n",
      "|    upright              | 144        |\n",
      "|    velocity_penalty     | -10.5      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 956        |\n",
      "|    ep_rew_mean          | 2.2e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1810       |\n",
      "|    iterations           | 264        |\n",
      "|    time_elapsed         | 3583       |\n",
      "|    total_timesteps      | 6488064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01627241 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.00074    |\n",
      "|    loss                 | 184        |\n",
      "|    n_updates            | 2630       |\n",
      "|    policy_gradient_loss | -0.009     |\n",
      "|    std                  | 0.693      |\n",
      "|    value_loss           | 337        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 247         |\n",
      "|    position_penalty     | -176        |\n",
      "|    time                 | 337         |\n",
      "|    torque_penalty       | -101        |\n",
      "|    upright              | 240         |\n",
      "|    velocity_penalty     | -32.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 887         |\n",
      "|    ep_rew_mean          | 2.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1810        |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 3596        |\n",
      "|    total_timesteps      | 6512640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012851915 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000735    |\n",
      "|    loss                 | 234         |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 374         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 152         |\n",
      "|    position_penalty     | -102        |\n",
      "|    time                 | 214         |\n",
      "|    torque_penalty       | -63.9       |\n",
      "|    upright              | 133         |\n",
      "|    velocity_penalty     | -17.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 993         |\n",
      "|    ep_rew_mean          | 2.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1810        |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 3609        |\n",
      "|    total_timesteps      | 6537216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012962493 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00073     |\n",
      "|    loss                 | 80.6        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 4.79e+03     |\n",
      "|    position_penalty     | -518         |\n",
      "|    time                 | 4.8e+03      |\n",
      "|    torque_penalty       | -1.44e+03    |\n",
      "|    upright              | 4.58e+03     |\n",
      "|    velocity_penalty     | -91.9        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 808          |\n",
      "|    ep_rew_mean          | 1.82e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1811         |\n",
      "|    iterations           | 267          |\n",
      "|    time_elapsed         | 3623         |\n",
      "|    total_timesteps      | 6561792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137915835 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.5        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.000725     |\n",
      "|    loss                 | 251          |\n",
      "|    n_updates            | 2660         |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 0.695        |\n",
      "|    value_loss           | 461          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.77e+03    |\n",
      "|    position_penalty     | -458        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.57e+03    |\n",
      "|    velocity_penalty     | -107        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 866         |\n",
      "|    ep_rew_mean          | 1.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 3636        |\n",
      "|    total_timesteps      | 6586368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015909253 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.00072     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 110         |\n",
      "|    position_penalty     | -38.2       |\n",
      "|    time                 | 132         |\n",
      "|    torque_penalty       | -39.6       |\n",
      "|    upright              | 64.9        |\n",
      "|    velocity_penalty     | -10         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 892         |\n",
      "|    ep_rew_mean          | 2.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 3649        |\n",
      "|    total_timesteps      | 6610944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013232775 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000716    |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 98.9        |\n",
      "|    position_penalty     | -55.1       |\n",
      "|    time                 | 148         |\n",
      "|    torque_penalty       | -44.4       |\n",
      "|    upright              | 86.2        |\n",
      "|    velocity_penalty     | -11.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 912         |\n",
      "|    ep_rew_mean          | 2.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 3663        |\n",
      "|    total_timesteps      | 6635520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013562613 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000711    |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 384         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -430        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.48e+03    |\n",
      "|    velocity_penalty     | -103        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 894         |\n",
      "|    ep_rew_mean          | 2.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 3676        |\n",
      "|    total_timesteps      | 6660096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012255225 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.000706    |\n",
      "|    loss                 | 80          |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 1.14e+03    |\n",
      "|    position_penalty     | -320        |\n",
      "|    time                 | 1.28e+03    |\n",
      "|    torque_penalty       | -383        |\n",
      "|    upright              | 1.08e+03    |\n",
      "|    velocity_penalty     | -31.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 756         |\n",
      "|    ep_rew_mean          | 1.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 3689        |\n",
      "|    total_timesteps      | 6684672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015151878 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000701    |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 123         |\n",
      "|    position_penalty     | -43.9       |\n",
      "|    time                 | 165         |\n",
      "|    torque_penalty       | -49.2       |\n",
      "|    upright              | 70.1        |\n",
      "|    velocity_penalty     | -8.56       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 862         |\n",
      "|    ep_rew_mean          | 1.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 3703        |\n",
      "|    total_timesteps      | 6709248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014399803 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.000696    |\n",
      "|    loss                 | 54.5        |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 125         |\n",
      "|    position_penalty     | -52         |\n",
      "|    time                 | 197         |\n",
      "|    torque_penalty       | -59         |\n",
      "|    upright              | 132         |\n",
      "|    velocity_penalty     | -10         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 890         |\n",
      "|    ep_rew_mean          | 2.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 3716        |\n",
      "|    total_timesteps      | 6733824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013000615 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000692    |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 141         |\n",
      "|    position_penalty     | -86.2       |\n",
      "|    time                 | 206         |\n",
      "|    torque_penalty       | -61.7       |\n",
      "|    upright              | 104         |\n",
      "|    velocity_penalty     | -13.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 956         |\n",
      "|    ep_rew_mean          | 2.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 3729        |\n",
      "|    total_timesteps      | 6758400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017115755 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.000687    |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 133         |\n",
      "|    position_penalty     | -73.2       |\n",
      "|    time                 | 185         |\n",
      "|    torque_penalty       | -55.5       |\n",
      "|    upright              | 80.4        |\n",
      "|    velocity_penalty     | -10.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 2.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1812        |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 3743        |\n",
      "|    total_timesteps      | 6782976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014959943 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.000682    |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 124         |\n",
      "|    position_penalty     | -47         |\n",
      "|    time                 | 148         |\n",
      "|    torque_penalty       | -44.4       |\n",
      "|    upright              | 81.8        |\n",
      "|    velocity_penalty     | -9.74       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 2.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1812        |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 3756        |\n",
      "|    total_timesteps      | 6807552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014414159 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.000677    |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -440        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.65e+03    |\n",
      "|    velocity_penalty     | -91.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 2.78e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1812        |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 3769        |\n",
      "|    total_timesteps      | 6832128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014749204 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000673    |\n",
      "|    loss                 | 98.2        |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 92.3       |\n",
      "|    position_penalty     | -32.4      |\n",
      "|    time                 | 124        |\n",
      "|    torque_penalty       | -37.1      |\n",
      "|    upright              | 52         |\n",
      "|    velocity_penalty     | -8         |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.13e+03   |\n",
      "|    ep_rew_mean          | 2.67e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1812       |\n",
      "|    iterations           | 279        |\n",
      "|    time_elapsed         | 3783       |\n",
      "|    total_timesteps      | 6856704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01668012 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.000668   |\n",
      "|    loss                 | 158        |\n",
      "|    n_updates            | 2780       |\n",
      "|    policy_gradient_loss | -0.00889   |\n",
      "|    std                  | 0.692      |\n",
      "|    value_loss           | 351        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 91.8        |\n",
      "|    position_penalty     | -71.1       |\n",
      "|    time                 | 147         |\n",
      "|    torque_penalty       | -43.8       |\n",
      "|    upright              | 81          |\n",
      "|    velocity_penalty     | -12.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 2.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1812        |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 3796        |\n",
      "|    total_timesteps      | 6881280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012886278 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000663    |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 303         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 83.7        |\n",
      "|    position_penalty     | -69.9       |\n",
      "|    time                 | 139         |\n",
      "|    torque_penalty       | -41.4       |\n",
      "|    upright              | 68.3        |\n",
      "|    velocity_penalty     | -13.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | 2.67e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1812        |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 3809        |\n",
      "|    total_timesteps      | 6905856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020136632 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.000658    |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 134        |\n",
      "|    position_penalty     | -78.9      |\n",
      "|    time                 | 207        |\n",
      "|    torque_penalty       | -61.8      |\n",
      "|    upright              | 126        |\n",
      "|    velocity_penalty     | -12.4      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.12e+03   |\n",
      "|    ep_rew_mean          | 2.64e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1812       |\n",
      "|    iterations           | 282        |\n",
      "|    time_elapsed         | 3823       |\n",
      "|    total_timesteps      | 6930432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01650733 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.000653   |\n",
      "|    loss                 | 24.2       |\n",
      "|    n_updates            | 2810       |\n",
      "|    policy_gradient_loss | -0.00621   |\n",
      "|    std                  | 0.691      |\n",
      "|    value_loss           | 86.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 104         |\n",
      "|    position_penalty     | -70.7       |\n",
      "|    time                 | 168         |\n",
      "|    torque_penalty       | -50.2       |\n",
      "|    upright              | 96.8        |\n",
      "|    velocity_penalty     | -11.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1812        |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 3836        |\n",
      "|    total_timesteps      | 6955008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017581383 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.000649    |\n",
      "|    loss                 | 281         |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 514         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 168        |\n",
      "|    position_penalty     | -65.9      |\n",
      "|    time                 | 246        |\n",
      "|    torque_penalty       | -73.8      |\n",
      "|    upright              | 169        |\n",
      "|    velocity_penalty     | -10.4      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.05e+03   |\n",
      "|    ep_rew_mean          | 2.45e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1812       |\n",
      "|    iterations           | 284        |\n",
      "|    time_elapsed         | 3849       |\n",
      "|    total_timesteps      | 6979584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01515077 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.000644   |\n",
      "|    loss                 | 214        |\n",
      "|    n_updates            | 2830       |\n",
      "|    policy_gradient_loss | -0.00912   |\n",
      "|    std                  | 0.693      |\n",
      "|    value_loss           | 383        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 130         |\n",
      "|    position_penalty     | -78.3       |\n",
      "|    time                 | 193         |\n",
      "|    torque_penalty       | -57.6       |\n",
      "|    upright              | 119         |\n",
      "|    velocity_penalty     | -13.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 2.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 3863        |\n",
      "|    total_timesteps      | 7004160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012066823 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000639    |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 170         |\n",
      "|    position_penalty     | -113        |\n",
      "|    time                 | 235         |\n",
      "|    torque_penalty       | -70.4       |\n",
      "|    upright              | 136         |\n",
      "|    velocity_penalty     | -24         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 3876        |\n",
      "|    total_timesteps      | 7028736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020436011 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000634    |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.75e+03    |\n",
      "|    position_penalty     | -649        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.62e+03    |\n",
      "|    velocity_penalty     | -105        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 2.59e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 3889        |\n",
      "|    total_timesteps      | 7053312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017406961 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.000629    |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 180         |\n",
      "|    position_penalty     | -61.7       |\n",
      "|    time                 | 208         |\n",
      "|    torque_penalty       | -62         |\n",
      "|    upright              | 121         |\n",
      "|    velocity_penalty     | -10.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 863         |\n",
      "|    ep_rew_mean          | 2e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 3903        |\n",
      "|    total_timesteps      | 7077888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013897249 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.000625    |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 702         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 151         |\n",
      "|    position_penalty     | -52.7       |\n",
      "|    time                 | 216         |\n",
      "|    torque_penalty       | -64.3       |\n",
      "|    upright              | 99.2        |\n",
      "|    velocity_penalty     | -9.88       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 790         |\n",
      "|    ep_rew_mean          | 1.78e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 3916        |\n",
      "|    total_timesteps      | 7102464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843935 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.00062     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 206         |\n",
      "|    position_penalty     | -104        |\n",
      "|    time                 | 293         |\n",
      "|    torque_penalty       | -87.7       |\n",
      "|    upright              | 200         |\n",
      "|    velocity_penalty     | -13.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 701         |\n",
      "|    ep_rew_mean          | 1.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 3929        |\n",
      "|    total_timesteps      | 7127040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016130371 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.000615    |\n",
      "|    loss                 | 58.5        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 90.1        |\n",
      "|    position_penalty     | -74.3       |\n",
      "|    time                 | 144         |\n",
      "|    torque_penalty       | -43         |\n",
      "|    upright              | 71.7        |\n",
      "|    velocity_penalty     | -14.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 841         |\n",
      "|    ep_rew_mean          | 1.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 3943        |\n",
      "|    total_timesteps      | 7151616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017699083 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.00061     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 109         |\n",
      "|    position_penalty     | -50.2       |\n",
      "|    time                 | 141         |\n",
      "|    torque_penalty       | -42.2       |\n",
      "|    upright              | 71.3        |\n",
      "|    velocity_penalty     | -10.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 2.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 3956        |\n",
      "|    total_timesteps      | 7176192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018338127 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.000605    |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 315         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 60.2       |\n",
      "|    position_penalty     | -35.7      |\n",
      "|    time                 | 117        |\n",
      "|    torque_penalty       | -35        |\n",
      "|    upright              | 65.8       |\n",
      "|    velocity_penalty     | -8.54      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.14e+03   |\n",
      "|    ep_rew_mean          | 2.71e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1813       |\n",
      "|    iterations           | 293        |\n",
      "|    time_elapsed         | 3969       |\n",
      "|    total_timesteps      | 7200768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01727312 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.4      |\n",
      "|    explained_variance   | 0.942      |\n",
      "|    learning_rate        | 0.000601   |\n",
      "|    loss                 | 258        |\n",
      "|    n_updates            | 2920       |\n",
      "|    policy_gradient_loss | -0.00862   |\n",
      "|    std                  | 0.694      |\n",
      "|    value_loss           | 548        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 86.7        |\n",
      "|    position_penalty     | -46.7       |\n",
      "|    time                 | 150         |\n",
      "|    torque_penalty       | -44.9       |\n",
      "|    upright              | 85.8        |\n",
      "|    velocity_penalty     | -9.23       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 2.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1813        |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 3983        |\n",
      "|    total_timesteps      | 7225344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013614525 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000596    |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 438         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 183         |\n",
      "|    position_penalty     | -82.5       |\n",
      "|    time                 | 268         |\n",
      "|    torque_penalty       | -80.2       |\n",
      "|    upright              | 206         |\n",
      "|    velocity_penalty     | -11.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | 2.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 3996        |\n",
      "|    total_timesteps      | 7249920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017530942 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000591    |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 372         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -461        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.69e+03    |\n",
      "|    velocity_penalty     | -97.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 964         |\n",
      "|    ep_rew_mean          | 2.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 4009        |\n",
      "|    total_timesteps      | 7274496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013963997 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.000586    |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 439         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 62.1        |\n",
      "|    position_penalty     | -38.3       |\n",
      "|    time                 | 120         |\n",
      "|    torque_penalty       | -35.8       |\n",
      "|    upright              | 69.3        |\n",
      "|    velocity_penalty     | -9.01       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 878         |\n",
      "|    ep_rew_mean          | 2.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 4023        |\n",
      "|    total_timesteps      | 7299072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012753304 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.000581    |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 78.4        |\n",
      "|    position_penalty     | -39.9       |\n",
      "|    time                 | 137         |\n",
      "|    torque_penalty       | -41         |\n",
      "|    upright              | 81.4        |\n",
      "|    velocity_penalty     | -9.95       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 2.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 4036        |\n",
      "|    total_timesteps      | 7323648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023563003 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.000577    |\n",
      "|    loss                 | 82.3        |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 60.4        |\n",
      "|    position_penalty     | -34.5       |\n",
      "|    time                 | 118         |\n",
      "|    torque_penalty       | -35.3       |\n",
      "|    upright              | 63.9        |\n",
      "|    velocity_penalty     | -8.91       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 910         |\n",
      "|    ep_rew_mean          | 2.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 4050        |\n",
      "|    total_timesteps      | 7348224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018949552 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.000572    |\n",
      "|    loss                 | 305         |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 657         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -351        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.6e+03     |\n",
      "|    velocity_penalty     | -98.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 947         |\n",
      "|    ep_rew_mean          | 2.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 4063        |\n",
      "|    total_timesteps      | 7372800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810995 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000567    |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 77.5        |\n",
      "|    position_penalty     | -42.4       |\n",
      "|    time                 | 143         |\n",
      "|    torque_penalty       | -42.7       |\n",
      "|    upright              | 77.4        |\n",
      "|    velocity_penalty     | -9.66       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 782         |\n",
      "|    ep_rew_mean          | 1.79e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 4076        |\n",
      "|    total_timesteps      | 7397376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015495914 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.000562    |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 366         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -810        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.61e+03    |\n",
      "|    velocity_penalty     | -98.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 842         |\n",
      "|    ep_rew_mean          | 1.94e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 4090        |\n",
      "|    total_timesteps      | 7421952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011891457 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.000558    |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 112         |\n",
      "|    position_penalty     | -49.5       |\n",
      "|    time                 | 181         |\n",
      "|    torque_penalty       | -54.1       |\n",
      "|    upright              | 114         |\n",
      "|    velocity_penalty     | -9.79       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 848         |\n",
      "|    ep_rew_mean          | 1.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 4103        |\n",
      "|    total_timesteps      | 7446528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013907167 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000553    |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 432         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 335         |\n",
      "|    position_penalty     | -110        |\n",
      "|    time                 | 386         |\n",
      "|    torque_penalty       | -116        |\n",
      "|    upright              | 148         |\n",
      "|    velocity_penalty     | -16.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 845         |\n",
      "|    ep_rew_mean          | 1.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 4116        |\n",
      "|    total_timesteps      | 7471104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013035114 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.000548    |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 190         |\n",
      "|    position_penalty     | -118        |\n",
      "|    time                 | 258         |\n",
      "|    torque_penalty       | -76.6       |\n",
      "|    upright              | 176         |\n",
      "|    velocity_penalty     | -17.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 844         |\n",
      "|    ep_rew_mean          | 1.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1814        |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 4130        |\n",
      "|    total_timesteps      | 7495680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011096063 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.000543    |\n",
      "|    loss                 | 239         |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 465         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 4.77e+03   |\n",
      "|    position_penalty     | -386       |\n",
      "|    time                 | 4.8e+03    |\n",
      "|    torque_penalty       | -1.44e+03  |\n",
      "|    upright              | 4.53e+03   |\n",
      "|    velocity_penalty     | -111       |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 886        |\n",
      "|    ep_rew_mean          | 2.03e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1814       |\n",
      "|    iterations           | 306        |\n",
      "|    time_elapsed         | 4143       |\n",
      "|    total_timesteps      | 7520256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01072728 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.000538   |\n",
      "|    loss                 | 175        |\n",
      "|    n_updates            | 3050       |\n",
      "|    policy_gradient_loss | -0.00938   |\n",
      "|    std                  | 0.697      |\n",
      "|    value_loss           | 372        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 117        |\n",
      "|    position_penalty     | -88.9      |\n",
      "|    time                 | 194        |\n",
      "|    torque_penalty       | -57.9      |\n",
      "|    upright              | 112        |\n",
      "|    velocity_penalty     | -14.4      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 861        |\n",
      "|    ep_rew_mean          | 1.97e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1815       |\n",
      "|    iterations           | 307        |\n",
      "|    time_elapsed         | 4156       |\n",
      "|    total_timesteps      | 7544832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01357172 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.000534   |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 3060       |\n",
      "|    policy_gradient_loss | -0.00889   |\n",
      "|    std                  | 0.697      |\n",
      "|    value_loss           | 251        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 252          |\n",
      "|    position_penalty     | -95.9        |\n",
      "|    time                 | 334          |\n",
      "|    torque_penalty       | -100         |\n",
      "|    upright              | 269          |\n",
      "|    velocity_penalty     | -14.3        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 799          |\n",
      "|    ep_rew_mean          | 1.83e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1815         |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 4170         |\n",
      "|    total_timesteps      | 7569408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121467905 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.5        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.000529     |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 3070         |\n",
      "|    policy_gradient_loss | -0.00912     |\n",
      "|    std                  | 0.698        |\n",
      "|    value_loss           | 380          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -404        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.65e+03    |\n",
      "|    velocity_penalty     | -112        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 944         |\n",
      "|    ep_rew_mean          | 2.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 4183        |\n",
      "|    total_timesteps      | 7593984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012536864 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.000524    |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 65.8        |\n",
      "|    position_penalty     | -39.9       |\n",
      "|    time                 | 130         |\n",
      "|    torque_penalty       | -38.8       |\n",
      "|    upright              | 71.8        |\n",
      "|    velocity_penalty     | -10.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 918         |\n",
      "|    ep_rew_mean          | 2.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 4196        |\n",
      "|    total_timesteps      | 7618560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013499386 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.000519    |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 152         |\n",
      "|    position_penalty     | -143        |\n",
      "|    time                 | 277         |\n",
      "|    torque_penalty       | -83         |\n",
      "|    upright              | 127         |\n",
      "|    velocity_penalty     | -29.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 940         |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 4210        |\n",
      "|    total_timesteps      | 7643136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011402998 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000514    |\n",
      "|    loss                 | 234         |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 481         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 202          |\n",
      "|    position_penalty     | -59.6        |\n",
      "|    time                 | 227          |\n",
      "|    torque_penalty       | -67.8        |\n",
      "|    upright              | 107          |\n",
      "|    velocity_penalty     | -11.4        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 910          |\n",
      "|    ep_rew_mean          | 2.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1815         |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 4223         |\n",
      "|    total_timesteps      | 7667712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111864405 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.5        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.00051      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 3110         |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 0.7          |\n",
      "|    value_loss           | 286          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 126         |\n",
      "|    position_penalty     | -100        |\n",
      "|    time                 | 181         |\n",
      "|    torque_penalty       | -54         |\n",
      "|    upright              | 108         |\n",
      "|    velocity_penalty     | -17.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 833         |\n",
      "|    ep_rew_mean          | 1.9e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 4236        |\n",
      "|    total_timesteps      | 7692288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013059739 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.000505    |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.76e+03    |\n",
      "|    position_penalty     | -840        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.57e+03    |\n",
      "|    velocity_penalty     | -119        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 889         |\n",
      "|    ep_rew_mean          | 2.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 4250        |\n",
      "|    total_timesteps      | 7716864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011831491 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 554         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 120         |\n",
      "|    position_penalty     | -36.5       |\n",
      "|    time                 | 147         |\n",
      "|    torque_penalty       | -43.9       |\n",
      "|    upright              | 63.5        |\n",
      "|    velocity_penalty     | -10.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 925         |\n",
      "|    ep_rew_mean          | 2.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 4263        |\n",
      "|    total_timesteps      | 7741440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015051603 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000495    |\n",
      "|    loss                 | 87.5        |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 131         |\n",
      "|    position_penalty     | -38.6       |\n",
      "|    time                 | 157         |\n",
      "|    torque_penalty       | -46.9       |\n",
      "|    upright              | 77.5        |\n",
      "|    velocity_penalty     | -9.67       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 2.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 4276        |\n",
      "|    total_timesteps      | 7766016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016925579 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.00049     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 73.9        |\n",
      "|    position_penalty     | -40.7       |\n",
      "|    time                 | 135         |\n",
      "|    torque_penalty       | -40.3       |\n",
      "|    upright              | 79.5        |\n",
      "|    velocity_penalty     | -8.96       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 2.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1815        |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 4290        |\n",
      "|    total_timesteps      | 7790592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014632821 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.000486    |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 528         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 99          |\n",
      "|    position_penalty     | -40.3       |\n",
      "|    time                 | 168         |\n",
      "|    torque_penalty       | -50.2       |\n",
      "|    upright              | 72.9        |\n",
      "|    velocity_penalty     | -12         |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 2.99e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 4303        |\n",
      "|    total_timesteps      | 7815168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014883686 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.000481    |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 393         |\n",
      "|    position_penalty     | -148        |\n",
      "|    time                 | 503         |\n",
      "|    torque_penalty       | -151        |\n",
      "|    upright              | 357         |\n",
      "|    velocity_penalty     | -23.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 3.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 4316        |\n",
      "|    total_timesteps      | 7839744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015886286 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.000476    |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 527         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 86.3        |\n",
      "|    position_penalty     | -69.7       |\n",
      "|    time                 | 138         |\n",
      "|    torque_penalty       | -41.3       |\n",
      "|    upright              | 73.2        |\n",
      "|    velocity_penalty     | -13.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 3.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 4330        |\n",
      "|    total_timesteps      | 7864320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019783663 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.000471    |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 375         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 188          |\n",
      "|    position_penalty     | -171         |\n",
      "|    time                 | 326          |\n",
      "|    torque_penalty       | -97.3        |\n",
      "|    upright              | 190          |\n",
      "|    velocity_penalty     | -35          |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | 2.99e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1816         |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 4343         |\n",
      "|    total_timesteps      | 7888896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135873435 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.5        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.000466     |\n",
      "|    loss                 | 275          |\n",
      "|    n_updates            | 3200         |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    std                  | 0.697        |\n",
      "|    value_loss           | 467          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 131         |\n",
      "|    position_penalty     | -57.8       |\n",
      "|    time                 | 201         |\n",
      "|    torque_penalty       | -60.3       |\n",
      "|    upright              | 138         |\n",
      "|    velocity_penalty     | -11.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | 2.67e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 4357        |\n",
      "|    total_timesteps      | 7913472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012662579 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000462    |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 388         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 3.63e+03    |\n",
      "|    position_penalty     | -334        |\n",
      "|    time                 | 3.74e+03    |\n",
      "|    torque_penalty       | -1.12e+03   |\n",
      "|    upright              | 3.46e+03    |\n",
      "|    velocity_penalty     | -88.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 2.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 4370        |\n",
      "|    total_timesteps      | 7938048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013002567 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.000457    |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 87          |\n",
      "|    position_penalty     | -44.7       |\n",
      "|    time                 | 151         |\n",
      "|    torque_penalty       | -45.2       |\n",
      "|    upright              | 85.4        |\n",
      "|    velocity_penalty     | -10.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 762         |\n",
      "|    ep_rew_mean          | 1.71e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 4383        |\n",
      "|    total_timesteps      | 7962624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013340636 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.000452    |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 581         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 193         |\n",
      "|    position_penalty     | -151        |\n",
      "|    time                 | 306         |\n",
      "|    torque_penalty       | -91.2       |\n",
      "|    upright              | 191         |\n",
      "|    velocity_penalty     | -28.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 901         |\n",
      "|    ep_rew_mean          | 2.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 4397        |\n",
      "|    total_timesteps      | 7987200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011001059 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.000447    |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 903         |\n",
      "|    position_penalty     | -185        |\n",
      "|    time                 | 1e+03       |\n",
      "|    torque_penalty       | -300        |\n",
      "|    upright              | 669         |\n",
      "|    velocity_penalty     | -39.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 793         |\n",
      "|    ep_rew_mean          | 1.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 4410        |\n",
      "|    total_timesteps      | 8011776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013082765 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.000442    |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 477         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 101         |\n",
      "|    position_penalty     | -50.2       |\n",
      "|    time                 | 185         |\n",
      "|    torque_penalty       | -55.2       |\n",
      "|    upright              | 86.2        |\n",
      "|    velocity_penalty     | -15.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 795         |\n",
      "|    ep_rew_mean          | 1.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 4424        |\n",
      "|    total_timesteps      | 8036352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010289416 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.000438    |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 67.4        |\n",
      "|    position_penalty     | -36.2       |\n",
      "|    time                 | 122         |\n",
      "|    torque_penalty       | -36.5       |\n",
      "|    upright              | 62          |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 785         |\n",
      "|    ep_rew_mean          | 1.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 4437        |\n",
      "|    total_timesteps      | 8060928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012581439 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.000433    |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 369         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 95.3        |\n",
      "|    position_penalty     | -51.7       |\n",
      "|    time                 | 147         |\n",
      "|    torque_penalty       | -44.1       |\n",
      "|    upright              | 68.8        |\n",
      "|    velocity_penalty     | -12.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 728         |\n",
      "|    ep_rew_mean          | 1.65e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 4450        |\n",
      "|    total_timesteps      | 8085504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011679581 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.000428    |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| reward_components/      |           |\n",
      "|    height               | 88        |\n",
      "|    position_penalty     | -34.4     |\n",
      "|    time                 | 129       |\n",
      "|    torque_penalty       | -38.6     |\n",
      "|    upright              | 52.8      |\n",
      "|    velocity_penalty     | -10.2     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 733       |\n",
      "|    ep_rew_mean          | 1.66e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1816      |\n",
      "|    iterations           | 330       |\n",
      "|    time_elapsed         | 4464      |\n",
      "|    total_timesteps      | 8110080   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0124464 |\n",
      "|    clip_fraction        | 0.201     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -12.5     |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.000423  |\n",
      "|    loss                 | 194       |\n",
      "|    n_updates            | 3290      |\n",
      "|    policy_gradient_loss | -0.00843  |\n",
      "|    std                  | 0.695     |\n",
      "|    value_loss           | 376       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 63         |\n",
      "|    position_penalty     | -31.9      |\n",
      "|    time                 | 119        |\n",
      "|    torque_penalty       | -35.7      |\n",
      "|    upright              | 57.5       |\n",
      "|    velocity_penalty     | -9.31      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 725        |\n",
      "|    ep_rew_mean          | 1.64e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1816       |\n",
      "|    iterations           | 331        |\n",
      "|    time_elapsed         | 4477       |\n",
      "|    total_timesteps      | 8134656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01214392 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.000419   |\n",
      "|    loss                 | 264        |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | -0.00893   |\n",
      "|    std                  | 0.695      |\n",
      "|    value_loss           | 467        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 242         |\n",
      "|    position_penalty     | -131        |\n",
      "|    time                 | 327         |\n",
      "|    torque_penalty       | -97.6       |\n",
      "|    upright              | 196         |\n",
      "|    velocity_penalty     | -18.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 844         |\n",
      "|    ep_rew_mean          | 1.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1816        |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 4490        |\n",
      "|    total_timesteps      | 8159232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843297 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.000414    |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| reward_components/      |           |\n",
      "|    height               | 188       |\n",
      "|    position_penalty     | -179      |\n",
      "|    time                 | 285       |\n",
      "|    torque_penalty       | -85.4     |\n",
      "|    upright              | 156       |\n",
      "|    velocity_penalty     | -33.7     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 975       |\n",
      "|    ep_rew_mean          | 2.29e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1816      |\n",
      "|    iterations           | 333       |\n",
      "|    time_elapsed         | 4504      |\n",
      "|    total_timesteps      | 8183808   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0175339 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -12.5     |\n",
      "|    explained_variance   | 0.978     |\n",
      "|    learning_rate        | 0.000409  |\n",
      "|    loss                 | 141       |\n",
      "|    n_updates            | 3320      |\n",
      "|    policy_gradient_loss | -0.00866  |\n",
      "|    std                  | 0.694     |\n",
      "|    value_loss           | 279       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 163          |\n",
      "|    position_penalty     | -104         |\n",
      "|    time                 | 228          |\n",
      "|    torque_penalty       | -67.7        |\n",
      "|    upright              | 154          |\n",
      "|    velocity_penalty     | -16          |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | 2.39e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1817         |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 4517         |\n",
      "|    total_timesteps      | 8208384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128504755 |\n",
      "|    clip_fraction        | 0.249        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.5        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.000404     |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 3330         |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.694        |\n",
      "|    value_loss           | 443          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 74.2         |\n",
      "|    position_penalty     | -37.4        |\n",
      "|    time                 | 133          |\n",
      "|    torque_penalty       | -39.5        |\n",
      "|    upright              | 58.4         |\n",
      "|    velocity_penalty     | -13.1        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 978          |\n",
      "|    ep_rew_mean          | 2.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1817         |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 4530         |\n",
      "|    total_timesteps      | 8232960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111240195 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.5        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.000399     |\n",
      "|    loss                 | 98.2         |\n",
      "|    n_updates            | 3340         |\n",
      "|    policy_gradient_loss | -0.00912     |\n",
      "|    std                  | 0.695        |\n",
      "|    value_loss           | 302          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 300         |\n",
      "|    position_penalty     | -141        |\n",
      "|    time                 | 374         |\n",
      "|    torque_penalty       | -112        |\n",
      "|    upright              | 139         |\n",
      "|    velocity_penalty     | -29.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 908         |\n",
      "|    ep_rew_mean          | 2.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 4544        |\n",
      "|    total_timesteps      | 8257536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011884111 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000395    |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 72.6        |\n",
      "|    position_penalty     | -31.5       |\n",
      "|    time                 | 130         |\n",
      "|    torque_penalty       | -39         |\n",
      "|    upright              | 66.1        |\n",
      "|    velocity_penalty     | -9.5        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 815         |\n",
      "|    ep_rew_mean          | 1.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 4557        |\n",
      "|    total_timesteps      | 8282112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012074293 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.00039     |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 215        |\n",
      "|    position_penalty     | -164       |\n",
      "|    time                 | 342        |\n",
      "|    torque_penalty       | -102       |\n",
      "|    upright              | 140        |\n",
      "|    velocity_penalty     | -27.2      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 989        |\n",
      "|    ep_rew_mean          | 2.29e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1817       |\n",
      "|    iterations           | 338        |\n",
      "|    time_elapsed         | 4570       |\n",
      "|    total_timesteps      | 8306688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01184158 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.000385   |\n",
      "|    loss                 | 159        |\n",
      "|    n_updates            | 3370       |\n",
      "|    policy_gradient_loss | -0.00805   |\n",
      "|    std                  | 0.695      |\n",
      "|    value_loss           | 336        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 144         |\n",
      "|    position_penalty     | -53.9       |\n",
      "|    time                 | 215         |\n",
      "|    torque_penalty       | -64.2       |\n",
      "|    upright              | 102         |\n",
      "|    velocity_penalty     | -13.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 4584        |\n",
      "|    total_timesteps      | 8331264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014857948 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.00038     |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 538         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 163         |\n",
      "|    position_penalty     | -128        |\n",
      "|    time                 | 241         |\n",
      "|    torque_penalty       | -71.8       |\n",
      "|    upright              | 175         |\n",
      "|    velocity_penalty     | -21.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 3.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 4597        |\n",
      "|    total_timesteps      | 8355840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012637396 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000375    |\n",
      "|    loss                 | 58.3        |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -677        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.59e+03    |\n",
      "|    velocity_penalty     | -116        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 2.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 4610        |\n",
      "|    total_timesteps      | 8380416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015989961 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.000371    |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 579         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 87.2        |\n",
      "|    position_penalty     | -69.9       |\n",
      "|    time                 | 139         |\n",
      "|    torque_penalty       | -41.6       |\n",
      "|    upright              | 50.6        |\n",
      "|    velocity_penalty     | -16.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 2.62e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 4623        |\n",
      "|    total_timesteps      | 8404992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013140239 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.000366    |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 471         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 125        |\n",
      "|    position_penalty     | -72.4      |\n",
      "|    time                 | 198        |\n",
      "|    torque_penalty       | -59.3      |\n",
      "|    upright              | 116        |\n",
      "|    velocity_penalty     | -13        |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.06e+03   |\n",
      "|    ep_rew_mean          | 2.53e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1817       |\n",
      "|    iterations           | 343        |\n",
      "|    time_elapsed         | 4637       |\n",
      "|    total_timesteps      | 8429568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01093202 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.000361   |\n",
      "|    loss                 | 118        |\n",
      "|    n_updates            | 3420       |\n",
      "|    policy_gradient_loss | -0.00932   |\n",
      "|    std                  | 0.695      |\n",
      "|    value_loss           | 236        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 265         |\n",
      "|    position_penalty     | -166        |\n",
      "|    time                 | 339         |\n",
      "|    torque_penalty       | -101        |\n",
      "|    upright              | 241         |\n",
      "|    velocity_penalty     | -29.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 2.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 4650        |\n",
      "|    total_timesteps      | 8454144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011419461 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 272         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 106         |\n",
      "|    position_penalty     | -111        |\n",
      "|    time                 | 206         |\n",
      "|    torque_penalty       | -61.7       |\n",
      "|    upright              | 77.1        |\n",
      "|    velocity_penalty     | -29.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 2.64e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 4664        |\n",
      "|    total_timesteps      | 8478720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012200945 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.000351    |\n",
      "|    loss                 | 253         |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 469         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 1.87e+03    |\n",
      "|    position_penalty     | -524        |\n",
      "|    time                 | 1.99e+03    |\n",
      "|    torque_penalty       | -595        |\n",
      "|    upright              | 1.75e+03    |\n",
      "|    velocity_penalty     | -70.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 2.79e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 4677        |\n",
      "|    total_timesteps      | 8503296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012568957 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.000347    |\n",
      "|    loss                 | 96.3        |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 105         |\n",
      "|    position_penalty     | -126        |\n",
      "|    time                 | 190         |\n",
      "|    torque_penalty       | -56.9       |\n",
      "|    upright              | 81.5        |\n",
      "|    velocity_penalty     | -24.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 2.63e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 4690        |\n",
      "|    total_timesteps      | 8527872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010699302 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.000342    |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 87.8       |\n",
      "|    position_penalty     | -70.8      |\n",
      "|    time                 | 139        |\n",
      "|    torque_penalty       | -41.3      |\n",
      "|    upright              | 52         |\n",
      "|    velocity_penalty     | -16.8      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 956        |\n",
      "|    ep_rew_mean          | 2.23e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1818       |\n",
      "|    iterations           | 348        |\n",
      "|    time_elapsed         | 4704       |\n",
      "|    total_timesteps      | 8552448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01031077 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.5      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.000337   |\n",
      "|    loss                 | 226        |\n",
      "|    n_updates            | 3470       |\n",
      "|    policy_gradient_loss | -0.00792   |\n",
      "|    std                  | 0.695      |\n",
      "|    value_loss           | 429        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 63.2        |\n",
      "|    position_penalty     | -39.6       |\n",
      "|    time                 | 122         |\n",
      "|    torque_penalty       | -36.6       |\n",
      "|    upright              | 62.3        |\n",
      "|    velocity_penalty     | -8.43       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 657         |\n",
      "|    ep_rew_mean          | 1.46e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 4717        |\n",
      "|    total_timesteps      | 8577024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009710324 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.000332    |\n",
      "|    loss                 | 84          |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 148         |\n",
      "|    position_penalty     | -100        |\n",
      "|    time                 | 209         |\n",
      "|    torque_penalty       | -62.6       |\n",
      "|    upright              | 131         |\n",
      "|    velocity_penalty     | -18.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 700         |\n",
      "|    ep_rew_mean          | 1.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 4730        |\n",
      "|    total_timesteps      | 8601600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011060852 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000327    |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 345         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 251         |\n",
      "|    position_penalty     | -80.1       |\n",
      "|    time                 | 330         |\n",
      "|    torque_penalty       | -98.9       |\n",
      "|    upright              | 232         |\n",
      "|    velocity_penalty     | -14.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 934         |\n",
      "|    ep_rew_mean          | 2.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 4744        |\n",
      "|    total_timesteps      | 8626176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013219555 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000323    |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 73.7        |\n",
      "|    position_penalty     | -32.6       |\n",
      "|    time                 | 143         |\n",
      "|    torque_penalty       | -42.7       |\n",
      "|    upright              | 55.6        |\n",
      "|    velocity_penalty     | -13.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 2.64e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 4757        |\n",
      "|    total_timesteps      | 8650752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014328343 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.000318    |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 422         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -376        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.7e+03     |\n",
      "|    velocity_penalty     | -111        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 2.79e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 4770        |\n",
      "|    total_timesteps      | 8675328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013094499 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.000313    |\n",
      "|    loss                 | 239         |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 558         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 67          |\n",
      "|    position_penalty     | -30.2       |\n",
      "|    time                 | 125         |\n",
      "|    torque_penalty       | -37.1       |\n",
      "|    upright              | 64.5        |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 2.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 4784        |\n",
      "|    total_timesteps      | 8699904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010183853 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.000308    |\n",
      "|    loss                 | 95.6        |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 120         |\n",
      "|    position_penalty     | -45.5       |\n",
      "|    time                 | 187         |\n",
      "|    torque_penalty       | -56.1       |\n",
      "|    upright              | 111         |\n",
      "|    velocity_penalty     | -10.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | 3.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 4797        |\n",
      "|    total_timesteps      | 8724480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012180984 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.000304    |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 493         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -385        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.67e+03    |\n",
      "|    velocity_penalty     | -116        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 2.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 4811        |\n",
      "|    total_timesteps      | 8749056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013553537 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.000299    |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 197         |\n",
      "|    position_penalty     | -136        |\n",
      "|    time                 | 277         |\n",
      "|    torque_penalty       | -82.7       |\n",
      "|    upright              | 172         |\n",
      "|    velocity_penalty     | -25.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 2.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 4824        |\n",
      "|    total_timesteps      | 8773632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010721136 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.000294    |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 82.2        |\n",
      "|    position_penalty     | -35.3       |\n",
      "|    time                 | 134         |\n",
      "|    torque_penalty       | -40         |\n",
      "|    upright              | 44.3        |\n",
      "|    velocity_penalty     | -11.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 3.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 4837        |\n",
      "|    total_timesteps      | 8798208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013897111 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.000289    |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 580         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -526        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.65e+03    |\n",
      "|    velocity_penalty     | -107        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 3.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 4851        |\n",
      "|    total_timesteps      | 8822784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009531637 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.000284    |\n",
      "|    loss                 | 63.6        |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 113         |\n",
      "|    position_penalty     | -36.5       |\n",
      "|    time                 | 166         |\n",
      "|    torque_penalty       | -49.6       |\n",
      "|    upright              | 65.9        |\n",
      "|    velocity_penalty     | -11.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 2.99e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 4864        |\n",
      "|    total_timesteps      | 8847360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013142285 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.00028     |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 461         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -343        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.72e+03    |\n",
      "|    velocity_penalty     | -104        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 4878        |\n",
      "|    total_timesteps      | 8871936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011064425 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000275    |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 71.3        |\n",
      "|    position_penalty     | -33.5       |\n",
      "|    time                 | 130         |\n",
      "|    torque_penalty       | -38.9       |\n",
      "|    upright              | 63.2        |\n",
      "|    velocity_penalty     | -9          |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 2.61e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 4891        |\n",
      "|    total_timesteps      | 8896512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013977679 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.00027     |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 94.3        |\n",
      "|    position_penalty     | -59         |\n",
      "|    time                 | 160         |\n",
      "|    torque_penalty       | -47.9       |\n",
      "|    upright              | 85.5        |\n",
      "|    velocity_penalty     | -11.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 2.57e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 4905        |\n",
      "|    total_timesteps      | 8921088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012460996 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.000265    |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 119         |\n",
      "|    position_penalty     | -47.5       |\n",
      "|    time                 | 193         |\n",
      "|    torque_penalty       | -57.7       |\n",
      "|    upright              | 116         |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 2.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 4918        |\n",
      "|    total_timesteps      | 8945664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010735676 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.00026     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 398         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -407        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.7e+03     |\n",
      "|    velocity_penalty     | -103        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 2.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 4931        |\n",
      "|    total_timesteps      | 8970240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013303596 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000256    |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 446         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 2.17e+03    |\n",
      "|    position_penalty     | -261        |\n",
      "|    time                 | 2.25e+03    |\n",
      "|    torque_penalty       | -675        |\n",
      "|    upright              | 2.07e+03    |\n",
      "|    velocity_penalty     | -60.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 2.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 4945        |\n",
      "|    total_timesteps      | 8994816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011116327 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.000251    |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 110         |\n",
      "|    position_penalty     | -41.4       |\n",
      "|    time                 | 143         |\n",
      "|    torque_penalty       | -42.9       |\n",
      "|    upright              | 70.7        |\n",
      "|    velocity_penalty     | -11.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 2.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 4958        |\n",
      "|    total_timesteps      | 9019392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011776601 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.000246    |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 72.6        |\n",
      "|    position_penalty     | -43.7       |\n",
      "|    time                 | 133         |\n",
      "|    torque_penalty       | -39.9       |\n",
      "|    upright              | 67          |\n",
      "|    velocity_penalty     | -9.23       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 2.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 4972        |\n",
      "|    total_timesteps      | 9043968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013842476 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.000241    |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 448         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 257         |\n",
      "|    position_penalty     | -134        |\n",
      "|    time                 | 343         |\n",
      "|    torque_penalty       | -103        |\n",
      "|    upright              | 168         |\n",
      "|    velocity_penalty     | -19.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 2.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 4985        |\n",
      "|    total_timesteps      | 9068544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010519183 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000236    |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -366        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.7e+03     |\n",
      "|    velocity_penalty     | -103        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 3.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 4998        |\n",
      "|    total_timesteps      | 9093120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014591977 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.000232    |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 511         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 115         |\n",
      "|    position_penalty     | -53         |\n",
      "|    time                 | 164         |\n",
      "|    torque_penalty       | -49.2       |\n",
      "|    upright              | 103         |\n",
      "|    velocity_penalty     | -12.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 3.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 5011        |\n",
      "|    total_timesteps      | 9117696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014948116 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.000227    |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 366         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 186          |\n",
      "|    position_penalty     | -125         |\n",
      "|    time                 | 277          |\n",
      "|    torque_penalty       | -82.3        |\n",
      "|    upright              | 130          |\n",
      "|    velocity_penalty     | -18.3        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.66e+03     |\n",
      "|    ep_rew_mean          | 4.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1819         |\n",
      "|    iterations           | 372          |\n",
      "|    time_elapsed         | 5025         |\n",
      "|    total_timesteps      | 9142272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150943855 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.5        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.000222     |\n",
      "|    loss                 | 246          |\n",
      "|    n_updates            | 3710         |\n",
      "|    policy_gradient_loss | -0.00818     |\n",
      "|    std                  | 0.697        |\n",
      "|    value_loss           | 532          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 125         |\n",
      "|    position_penalty     | -39.9       |\n",
      "|    time                 | 197         |\n",
      "|    torque_penalty       | -58.9       |\n",
      "|    upright              | 77.7        |\n",
      "|    velocity_penalty     | -12.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 3.9e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 5038        |\n",
      "|    total_timesteps      | 9166848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014144492 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.000217    |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 3.41e+03    |\n",
      "|    position_penalty     | -516        |\n",
      "|    time                 | 3.51e+03    |\n",
      "|    torque_penalty       | -1.05e+03   |\n",
      "|    upright              | 3.18e+03    |\n",
      "|    velocity_penalty     | -97.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | 4e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 5051        |\n",
      "|    total_timesteps      | 9191424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011679034 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.000212    |\n",
      "|    loss                 | 247         |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 127         |\n",
      "|    position_penalty     | -64.9       |\n",
      "|    time                 | 202         |\n",
      "|    torque_penalty       | -60.3       |\n",
      "|    upright              | 134         |\n",
      "|    velocity_penalty     | -13.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | 4.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 5064        |\n",
      "|    total_timesteps      | 9216000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011809195 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.000208    |\n",
      "|    loss                 | 71.8        |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 93.1        |\n",
      "|    position_penalty     | -40.3       |\n",
      "|    time                 | 126         |\n",
      "|    torque_penalty       | -37.8       |\n",
      "|    upright              | 62          |\n",
      "|    velocity_penalty     | -12.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | 4e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 5078        |\n",
      "|    total_timesteps      | 9240576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015423288 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000203    |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 125         |\n",
      "|    position_penalty     | -55.3       |\n",
      "|    time                 | 175         |\n",
      "|    torque_penalty       | -52.5       |\n",
      "|    upright              | 95.5        |\n",
      "|    velocity_penalty     | -11.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 3.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 5091        |\n",
      "|    total_timesteps      | 9265152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013653214 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.000198    |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 544         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 332         |\n",
      "|    position_penalty     | -101        |\n",
      "|    time                 | 464         |\n",
      "|    torque_penalty       | -139        |\n",
      "|    upright              | 260         |\n",
      "|    velocity_penalty     | -19.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 3.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 5104        |\n",
      "|    total_timesteps      | 9289728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010406602 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000193    |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 263         |\n",
      "|    position_penalty     | -176        |\n",
      "|    time                 | 354         |\n",
      "|    torque_penalty       | -106        |\n",
      "|    upright              | 201         |\n",
      "|    velocity_penalty     | -32.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 3.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 5118        |\n",
      "|    total_timesteps      | 9314304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014144684 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.000189    |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    std                  | 0.701       |\n",
      "|    value_loss           | 567         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 114        |\n",
      "|    position_penalty     | -46.4      |\n",
      "|    time                 | 179        |\n",
      "|    torque_penalty       | -53.7      |\n",
      "|    upright              | 108        |\n",
      "|    velocity_penalty     | -12.1      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.19e+03   |\n",
      "|    ep_rew_mean          | 2.84e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1819       |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 5131       |\n",
      "|    total_timesteps      | 9338880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01106092 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.000184   |\n",
      "|    loss                 | 142        |\n",
      "|    n_updates            | 3790       |\n",
      "|    policy_gradient_loss | -0.00713   |\n",
      "|    std                  | 0.701      |\n",
      "|    value_loss           | 199        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 97.7        |\n",
      "|    position_penalty     | -42.4       |\n",
      "|    time                 | 160         |\n",
      "|    torque_penalty       | -47.9       |\n",
      "|    upright              | 93.3        |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 2.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1819        |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 5145        |\n",
      "|    total_timesteps      | 9363456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012198548 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.000179    |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 475         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 4.77e+03     |\n",
      "|    position_penalty     | -628         |\n",
      "|    time                 | 4.8e+03      |\n",
      "|    torque_penalty       | -1.44e+03    |\n",
      "|    upright              | 4.4e+03      |\n",
      "|    velocity_penalty     | -125         |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.16e+03     |\n",
      "|    ep_rew_mean          | 2.77e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1819         |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 5158         |\n",
      "|    total_timesteps      | 9388032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123640625 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.6        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.000174     |\n",
      "|    loss                 | 240          |\n",
      "|    n_updates            | 3810         |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    std                  | 0.703        |\n",
      "|    value_loss           | 464          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 1.27e+03    |\n",
      "|    position_penalty     | -304        |\n",
      "|    time                 | 1.41e+03    |\n",
      "|    torque_penalty       | -422        |\n",
      "|    upright              | 1.16e+03    |\n",
      "|    velocity_penalty     | -43.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | 2.69e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 5171        |\n",
      "|    total_timesteps      | 9412608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727961 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.000169    |\n",
      "|    loss                 | 77.4        |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 162         |\n",
      "|    position_penalty     | -126        |\n",
      "|    time                 | 231         |\n",
      "|    torque_penalty       | -68.2       |\n",
      "|    upright              | 138         |\n",
      "|    velocity_penalty     | -21.3       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 2.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 5185        |\n",
      "|    total_timesteps      | 9437184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010038369 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.000165    |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 121         |\n",
      "|    position_penalty     | -43.3       |\n",
      "|    time                 | 197         |\n",
      "|    torque_penalty       | -59         |\n",
      "|    upright              | 80.2        |\n",
      "|    velocity_penalty     | -13.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 2.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 5198        |\n",
      "|    total_timesteps      | 9461760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012704655 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.00016     |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 608         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -361        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.69e+03    |\n",
      "|    velocity_penalty     | -114        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 3.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 5211        |\n",
      "|    total_timesteps      | 9486336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010934141 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.000155    |\n",
      "|    loss                 | 85          |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 89.5       |\n",
      "|    position_penalty     | -42.7      |\n",
      "|    time                 | 154        |\n",
      "|    torque_penalty       | -45.9      |\n",
      "|    upright              | 88         |\n",
      "|    velocity_penalty     | -10.5      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.43e+03   |\n",
      "|    ep_rew_mean          | 3.42e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1820       |\n",
      "|    iterations           | 387        |\n",
      "|    time_elapsed         | 5225       |\n",
      "|    total_timesteps      | 9510912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01311665 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.00015    |\n",
      "|    loss                 | 226        |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | -0.00754   |\n",
      "|    std                  | 0.704      |\n",
      "|    value_loss           | 459        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -503        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.66e+03    |\n",
      "|    velocity_penalty     | -121        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | 3.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 5238        |\n",
      "|    total_timesteps      | 9535488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011272106 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000145    |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 166         |\n",
      "|    position_penalty     | -139        |\n",
      "|    time                 | 274         |\n",
      "|    torque_penalty       | -81.9       |\n",
      "|    upright              | 105         |\n",
      "|    velocity_penalty     | -29.7       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 3.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 5251        |\n",
      "|    total_timesteps      | 9560064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012898735 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000141    |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 86.6        |\n",
      "|    position_penalty     | -41.2       |\n",
      "|    time                 | 151         |\n",
      "|    torque_penalty       | -45.1       |\n",
      "|    upright              | 88.8        |\n",
      "|    velocity_penalty     | -9.31       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | 3.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 5264        |\n",
      "|    total_timesteps      | 9584640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009770326 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.000136    |\n",
      "|    loss                 | 87.6        |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.78e+03    |\n",
      "|    position_penalty     | -543        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.67e+03    |\n",
      "|    velocity_penalty     | -117        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 2.84e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 5278        |\n",
      "|    total_timesteps      | 9609216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011669249 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.000131    |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -454        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.67e+03    |\n",
      "|    velocity_penalty     | -114        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 2.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 5291        |\n",
      "|    total_timesteps      | 9633792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013650575 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.000126    |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -618        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.57e+03    |\n",
      "|    velocity_penalty     | -117        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | 3.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 5304        |\n",
      "|    total_timesteps      | 9658368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011160077 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.000121    |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 97.1        |\n",
      "|    position_penalty     | -56.5       |\n",
      "|    time                 | 129         |\n",
      "|    torque_penalty       | -38.7       |\n",
      "|    upright              | 58.9        |\n",
      "|    velocity_penalty     | -14.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | 3.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 5318        |\n",
      "|    total_timesteps      | 9682944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011511423 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.000117    |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 517         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 196         |\n",
      "|    position_penalty     | -117        |\n",
      "|    time                 | 291         |\n",
      "|    torque_penalty       | -87.2       |\n",
      "|    upright              | 150         |\n",
      "|    velocity_penalty     | -18.5       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 3e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 5331        |\n",
      "|    total_timesteps      | 9707520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013012391 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.000112    |\n",
      "|    loss                 | 89.2        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 138         |\n",
      "|    position_penalty     | -57         |\n",
      "|    time                 | 213         |\n",
      "|    torque_penalty       | -63.9       |\n",
      "|    upright              | 126         |\n",
      "|    velocity_penalty     | -11.9       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | 3.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 5344        |\n",
      "|    total_timesteps      | 9732096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012098327 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000107    |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 356         |\n",
      "|    position_penalty     | -166        |\n",
      "|    time                 | 452         |\n",
      "|    torque_penalty       | -135        |\n",
      "|    upright              | 269         |\n",
      "|    velocity_penalty     | -27.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 986         |\n",
      "|    ep_rew_mean          | 2.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 5358        |\n",
      "|    total_timesteps      | 9756672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009607722 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.000102    |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 515         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 122         |\n",
      "|    position_penalty     | -41.2       |\n",
      "|    time                 | 160         |\n",
      "|    torque_penalty       | -48         |\n",
      "|    upright              | 80.4        |\n",
      "|    velocity_penalty     | -13.6       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 927         |\n",
      "|    ep_rew_mean          | 2.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 5371        |\n",
      "|    total_timesteps      | 9781248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008365657 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 9.74e-05    |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 139         |\n",
      "|    position_penalty     | -54.6       |\n",
      "|    time                 | 212         |\n",
      "|    torque_penalty       | -63.6       |\n",
      "|    upright              | 143         |\n",
      "|    velocity_penalty     | -10.8       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 991         |\n",
      "|    ep_rew_mean          | 2.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1820        |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 5384        |\n",
      "|    total_timesteps      | 9805824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009764205 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 9.27e-05    |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 74.6        |\n",
      "|    position_penalty     | -36.2       |\n",
      "|    time                 | 131         |\n",
      "|    torque_penalty       | -39.2       |\n",
      "|    upright              | 73.6        |\n",
      "|    velocity_penalty     | -10.2       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 2.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1821        |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 5398        |\n",
      "|    total_timesteps      | 9830400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008498417 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 8.79e-05    |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 269         |\n",
      "|    position_penalty     | -165        |\n",
      "|    time                 | 384         |\n",
      "|    torque_penalty       | -115        |\n",
      "|    upright              | 270         |\n",
      "|    velocity_penalty     | -33.1       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 2.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1821        |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 5411        |\n",
      "|    total_timesteps      | 9854976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009016735 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 8.31e-05    |\n",
      "|    loss                 | 95.5        |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -402        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.66e+03    |\n",
      "|    velocity_penalty     | -109        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 3.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1821        |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 5424        |\n",
      "|    total_timesteps      | 9879552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008958495 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 7.83e-05    |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 284         |\n",
      "|    position_penalty     | -132        |\n",
      "|    time                 | 405         |\n",
      "|    torque_penalty       | -121        |\n",
      "|    upright              | 160         |\n",
      "|    velocity_penalty     | -29.4       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | 3.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1821        |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 5438        |\n",
      "|    total_timesteps      | 9904128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013616229 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 7.35e-05    |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 729         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| reward_components/      |            |\n",
      "|    height               | 125        |\n",
      "|    position_penalty     | -91.8      |\n",
      "|    time                 | 185        |\n",
      "|    torque_penalty       | -55.4      |\n",
      "|    upright              | 102        |\n",
      "|    velocity_penalty     | -17.1      |\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.18e+03   |\n",
      "|    ep_rew_mean          | 2.75e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1821       |\n",
      "|    iterations           | 404        |\n",
      "|    time_elapsed         | 5451       |\n",
      "|    total_timesteps      | 9928704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00803307 |\n",
      "|    clip_fraction        | 0.0558     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 6.87e-05   |\n",
      "|    loss                 | 122        |\n",
      "|    n_updates            | 4030       |\n",
      "|    policy_gradient_loss | -0.00486   |\n",
      "|    std                  | 0.706      |\n",
      "|    value_loss           | 214        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 4.79e+03    |\n",
      "|    position_penalty     | -380        |\n",
      "|    time                 | 4.8e+03     |\n",
      "|    torque_penalty       | -1.44e+03   |\n",
      "|    upright              | 4.65e+03    |\n",
      "|    velocity_penalty     | -109        |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1821        |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 5464        |\n",
      "|    total_timesteps      | 9953280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007523333 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 6.39e-05    |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| reward_components/      |              |\n",
      "|    height               | 122          |\n",
      "|    position_penalty     | -90.6        |\n",
      "|    time                 | 175          |\n",
      "|    torque_penalty       | -51.9        |\n",
      "|    upright              | 65.3         |\n",
      "|    velocity_penalty     | -18.5        |\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | 2.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1821         |\n",
      "|    iterations           | 406          |\n",
      "|    time_elapsed         | 5478         |\n",
      "|    total_timesteps      | 9977856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064998697 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.6        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5.91e-05     |\n",
      "|    loss                 | 303          |\n",
      "|    n_updates            | 4050         |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.705        |\n",
      "|    value_loss           | 562          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| reward_components/      |             |\n",
      "|    height               | 85          |\n",
      "|    position_penalty     | -41.9       |\n",
      "|    time                 | 151         |\n",
      "|    torque_penalty       | -45.2       |\n",
      "|    upright              | 93.8        |\n",
      "|    velocity_penalty     | -9.06       |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 2.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1821        |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 5491        |\n",
      "|    total_timesteps      | 10002432    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008647549 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5.43e-05    |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, CallbackList\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "model_name=\"test\"\n",
    "\n",
    "def linear_schedule(initial_value: float, final_value: float) -> callable:\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        return final_value + (initial_value - final_value) * progress_remaining\n",
    "\n",
    "    return func\n",
    "\n",
    "initial_lr = 2e-3\n",
    "final_lr = 5e-5\n",
    "lr_schedule = linear_schedule(initial_lr, final_lr)\n",
    "\n",
    "def make_env(render=False, task=\"stand\"):\n",
    "    def _init():\n",
    "        env = ExoskeletonEnv(render=render, task=task)\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "for _ in range(1):\n",
    "    num_envs = 12\n",
    "    env_fns = [make_env(render=False, task=\"stand\") for _ in range(num_envs)]\n",
    "    env = SubprocVecEnv(env_fns)\n",
    "\n",
    "    model = PPO(\"MlpPolicy\", \n",
    "                env, \n",
    "                verbose=1, \n",
    "                device='cpu',\n",
    "                tensorboard_log=\"./tensorboard\",\n",
    "                policy_kwargs = dict(\n",
    "                    net_arch=[256, 256]\n",
    "                    ),\n",
    "                batch_size=8192,\n",
    "                learning_rate=lr_schedule,\n",
    "                gamma=0.995,\n",
    "                )\n",
    "\n",
    "    checkpoint_callback = CheckpointCallback(save_freq=100_000, save_path='./checkpoints/', name_prefix=model_name)\n",
    "    components_callback = RewardComponentsCallback()\n",
    "\n",
    "    model.learn(total_timesteps=10_000_000,\n",
    "                callback=CallbackList([checkpoint_callback, components_callback]),\n",
    "                tb_log_name=model_name \n",
    "                )\n",
    "\n",
    "    model.save(model_name)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95f5231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 1...\n",
      "Episode 1 finished with total reward: 251.15710991186987\n",
      "Starting episode 2...\n",
      "Episode 2 finished with total reward: 179.68519555717629\n",
      "Starting episode 3...\n",
      "Episode 3 finished with total reward: 318.5548111028557\n",
      "Starting episode 4...\n",
      "Episode 4 finished with total reward: 683.8729674272269\n",
      "Starting episode 5...\n",
      "Episode 5 finished with total reward: 172.03064548758897\n",
      "Starting episode 6...\n",
      "Episode 6 finished with total reward: 253.69696028695924\n",
      "Starting episode 7...\n",
      "Episode 7 finished with total reward: 263.9772440661711\n",
      "Starting episode 8...\n",
      "Episode 8 finished with total reward: 519.9109157086391\n",
      "Starting episode 9...\n",
      "Episode 9 finished with total reward: 9051.012024616208\n",
      "Starting episode 10...\n",
      "Episode 10 finished with total reward: 549.6741646581829\n",
      "Starting episode 11...\n",
      "Episode 11 finished with total reward: 1527.9294157938677\n",
      "Starting episode 12...\n",
      "Episode 12 finished with total reward: 671.0734080913486\n",
      "Starting episode 13...\n",
      "Episode 13 finished with total reward: 338.2182708069676\n",
      "Starting episode 14...\n",
      "Episode 14 finished with total reward: 164.67132533101295\n",
      "Starting episode 15...\n",
      "Episode 15 finished with total reward: 3774.6516691671345\n",
      "Starting episode 16...\n",
      "Episode 16 finished with total reward: 1375.4013661203883\n",
      "Starting episode 17...\n",
      "Episode 17 finished with total reward: 395.1386465045427\n",
      "Starting episode 18...\n",
      "Episode 18 finished with total reward: 285.42430160441745\n",
      "Starting episode 19...\n",
      "Episode 19 finished with total reward: 215.51239295032602\n",
      "Starting episode 20...\n",
      "Episode 20 finished with total reward: 338.634426741528\n",
      "Starting episode 21...\n",
      "Episode 21 finished with total reward: 356.2956601214522\n",
      "Starting episode 22...\n",
      "Episode 22 finished with total reward: 2957.1124816940933\n",
      "Starting episode 23...\n",
      "Episode 23 finished with total reward: 195.76286115488733\n",
      "Starting episode 24...\n",
      "Episode 24 finished with total reward: 197.8733364927257\n",
      "Starting episode 25...\n",
      "Episode 25 finished with total reward: 442.2994922446931\n",
      "Starting episode 26...\n",
      "Episode 26 finished with total reward: 3140.020293271215\n",
      "Starting episode 27...\n",
      "Episode 27 finished with total reward: 780.9141616287271\n",
      "Starting episode 28...\n",
      "Episode 28 finished with total reward: 178.2563414493847\n",
      "Starting episode 29...\n",
      "Episode 29 finished with total reward: 167.1468170037817\n",
      "Starting episode 30...\n",
      "Episode 30 finished with total reward: 482.4252973173842\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import time\n",
    "\n",
    "env = ExoskeletonEnv(render=True, task=\"stand\")\n",
    "\n",
    "model = PPO.load(\"test\", device='cpu')\n",
    "\n",
    "num_episodes = 30\n",
    "for episode in range(num_episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    print(f\"Starting episode {episode+1}...\")\n",
    "    while not done:\n",
    "        # Use deterministic policy for testing.\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        time.sleep(1./240.)\n",
    "    print(f\"Episode {episode+1} finished with total reward: {total_reward}\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
